{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohsenJadidi/Automatic-Modulation-Classification-AMC/blob/master/AMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3svr4hy0fG3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbWAylFFl7H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR0ATiKBk6rG",
        "colab_type": "text"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfzzfiDSuxMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "fileName = 'RML2016.10a_dict.pkl'\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/\"+fileName,'rb') as f:\n",
        "  data = pickle.load(f,encoding='bytes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjAg9T-0uzyh",
        "colab_type": "code",
        "outputId": "9d883cfa-33e0-4489-c995-156be407255d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "X = []\n",
        "labels = [] # label each example by a pair (modulation type, snr)\n",
        "total_examples = 0\n",
        "analog = [b'AM-DSB', b'AM-SSB', b'WBFM']\n",
        "\n",
        "for mod_type, snr in data.keys():\n",
        "    if snr >=0 and (mod_type not in analog):      \n",
        "        current_matrix = data[(mod_type, snr)]        \n",
        "        total_examples += current_matrix.shape[0]\n",
        "        for i in range(current_matrix.shape[0]):\n",
        "            X.append(current_matrix[i])\n",
        "            labels.append((str(mod_type, 'ascii'), snr)) # mod_type is of type bytes\n",
        "    \n",
        "X = np.array(X)         # First row is QPSK snr=2, seconde is PAM4 snr=8 , ...\n",
        "labels = np.array(labels)\n",
        "\n",
        "y = labels[:,0]\n",
        "\n",
        "print(f'loaded {total_examples} signal vectors into X{X.shape} and their corresponding'\n",
        "      f' labels into labels{labels.shape}')  \n",
        "# print(np.unique(labels[:,0]))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded 80000 signal vectors into X(80000, 2, 128) and their corresponding labels into labels(80000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbeDr3FVv57v",
        "colab_type": "code",
        "outputId": "f314e5ed-5f78-46b8-c42a-5016683f8c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)\n",
        "onehotencoder = OneHotEncoder()\n",
        "y = onehotencoder.fit_transform(y.reshape(-1,1)).toarray()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6iUKbJwKlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "snrList = [str(2*i) for i in range(10)] \n",
        "snr = snrList[9]\n",
        "numberOfEachExamples = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DiHGfSPwKb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.reshape([X.shape[0],256])\n",
        "output = [[labels[i*numberOfEachExamples, 0],y[i*numberOfEachExamples]] for i in range(int(X.shape[0]/numberOfEachExamples))]\n",
        "output = dict(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OJ3GghKwrbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_snr = []\n",
        "y_snr = []\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "    if labels[i,1] == snr:\n",
        "        X_snr.append(X[i])\n",
        "        y_snr.append(y[i])\n",
        "\n",
        "X_snr = np.array(X_snr)\n",
        "y_snr = np.array(y_snr)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx7l0G_3ww0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### Splitting the dataset into the Training set and Test set ######\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 0.2, random_state = 0)\n",
        "# The below line better for Cross_val part\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 1, random_state = 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujxapqcRw1l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWipMIzTw3SN",
        "colab_type": "text"
      },
      "source": [
        "# Making model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t4bapTyw8Lp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "a32e5ab9-c201-4cb1-a233-2b388741d105"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "# Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))\n",
        "dout = 0.1\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-975a67ada2ce>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    classifier.compile(\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0K9N5wL2x3F",
        "colab_type": "code",
        "outputId": "7cc90398-af01-423a-f3f2-d0f385ea2f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "batch = 10\n",
        "epoch = 25\n",
        "classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "6400/6400 [==============================] - 1s 225us/step - loss: 1.7998 - acc: 0.2745\n",
            "Epoch 2/25\n",
            "6400/6400 [==============================] - 1s 172us/step - loss: 1.4987 - acc: 0.3847\n",
            "Epoch 3/25\n",
            "6400/6400 [==============================] - 1s 172us/step - loss: 1.3839 - acc: 0.4297\n",
            "Epoch 4/25\n",
            "6400/6400 [==============================] - 1s 174us/step - loss: 1.3183 - acc: 0.4506\n",
            "Epoch 5/25\n",
            "6400/6400 [==============================] - 1s 171us/step - loss: 1.2557 - acc: 0.4798\n",
            "Epoch 6/25\n",
            "6400/6400 [==============================] - 1s 171us/step - loss: 1.2134 - acc: 0.5084\n",
            "Epoch 7/25\n",
            "6400/6400 [==============================] - 1s 170us/step - loss: 1.1643 - acc: 0.5230\n",
            "Epoch 8/25\n",
            "6400/6400 [==============================] - 1s 171us/step - loss: 1.1309 - acc: 0.5377\n",
            "Epoch 9/25\n",
            "6400/6400 [==============================] - 1s 173us/step - loss: 1.0873 - acc: 0.5542\n",
            "Epoch 10/25\n",
            "6400/6400 [==============================] - 1s 172us/step - loss: 1.0465 - acc: 0.5791\n",
            "Epoch 11/25\n",
            "6400/6400 [==============================] - 1s 170us/step - loss: 1.0156 - acc: 0.5863\n",
            "Epoch 12/25\n",
            "6400/6400 [==============================] - 1s 174us/step - loss: 0.9991 - acc: 0.5919\n",
            "Epoch 13/25\n",
            "6400/6400 [==============================] - 1s 175us/step - loss: 0.9427 - acc: 0.6252\n",
            "Epoch 14/25\n",
            "6400/6400 [==============================] - 1s 179us/step - loss: 0.9093 - acc: 0.6341\n",
            "Epoch 15/25\n",
            "6400/6400 [==============================] - 1s 174us/step - loss: 0.8679 - acc: 0.6494\n",
            "Epoch 16/25\n",
            "6400/6400 [==============================] - 1s 179us/step - loss: 0.8753 - acc: 0.6472\n",
            "Epoch 17/25\n",
            "6400/6400 [==============================] - 1s 172us/step - loss: 0.8222 - acc: 0.6653\n",
            "Epoch 18/25\n",
            "6400/6400 [==============================] - 1s 172us/step - loss: 0.7956 - acc: 0.6856\n",
            "Epoch 19/25\n",
            "6400/6400 [==============================] - 1s 170us/step - loss: 0.7942 - acc: 0.6820\n",
            "Epoch 20/25\n",
            "6400/6400 [==============================] - 1s 170us/step - loss: 0.7661 - acc: 0.7028\n",
            "Epoch 21/25\n",
            "6400/6400 [==============================] - 1s 175us/step - loss: 0.7522 - acc: 0.7013\n",
            "Epoch 22/25\n",
            "6400/6400 [==============================] - 1s 177us/step - loss: 0.7234 - acc: 0.7156\n",
            "Epoch 23/25\n",
            "6400/6400 [==============================] - 1s 173us/step - loss: 0.7294 - acc: 0.7198\n",
            "Epoch 24/25\n",
            "6400/6400 [==============================] - 1s 179us/step - loss: 0.7185 - acc: 0.7147\n",
            "Epoch 25/25\n",
            "6400/6400 [==============================] - 1s 171us/step - loss: 0.6849 - acc: 0.7334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1977193fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6irYYHCZ6A2C",
        "colab_type": "code",
        "outputId": "95b610af-6ae9-4ca1-d02c-7d1940065120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_real = np.argmax(y_test, axis=1)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_real, y_pred)\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "acc_test = classifier.evaluate(X_test, y_test)[1]\n",
        "acc_train = classifier.evaluate(X_train, y_train)[1]\n",
        "\n",
        "print(\"Acc Test : \", acc_test)\n",
        "print(\"Acc Train : \", acc_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600/1600 [==============================] - 0s 77us/step\n",
            "6400/6400 [==============================] - 0s 25us/step\n",
            "Acc Test :  0.459375\n",
            "Acc Train :  0.87375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShXqOJL47hCE",
        "colab_type": "text"
      },
      "source": [
        "***Plot Confusion Matrix***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJdL7PP_7jir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "modulation_order = []\n",
        "modulation_order_dict = dict()\n",
        "\n",
        "for key,value in output.items():\n",
        "    modulation_order_dict[np.argmax(value)] = str(key)\n",
        "    \n",
        "for i in range(8):\n",
        "    modulation_order.append(modulation_order_dict[i])\n",
        "    \n",
        "    \n",
        "    \n",
        "cmDataFrame = pd.DataFrame(cm_norm, index=modulation_order, columns = modulation_order)\n",
        "plt.figure(figsize=(6, 5))\n",
        "ax = sns.heatmap(cmDataFrame, annot=True, annot_kws={\"size\": 8}, fmt='.2f', linewidths=.5, cmap=\"Greens\")\n",
        "\n",
        "plt.title(f\"AANN Confusion Matrix (SNR={snr})\")\n",
        "plt.xlabel(\"Predicted label  \\n\\n TrainAcc={:.2}, TestAcc={:.2}\".format(acc_train,acc_test), fontsize=8)\n",
        "plt.ylabel(\"True lable\", fontsize=8)\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\", fontsize=8)\n",
        "plt.setp(ax.get_yticklabels(), fontsize=8)\n",
        "fig = ax.get_figure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8eHSHvA7_ud",
        "colab_type": "code",
        "outputId": "e1ab8f19-4b10-4490-9ab9-8de33df7a5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "fig.savefig(dic+f\"ANN2-CrossVal-132-132-ba{batch}-ep{epoch}(SNR={snr}).png\", dpi=175, bbox_inches='tight')\n",
        "print(\"Plot Saved!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Plot Saved!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}