{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohsenJadidi/Automatic-Modulation-Classification-AMC/blob/master/AMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3svr4hy0fG3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbWAylFFl7H3",
        "colab_type": "code",
        "outputId": "6f8581d2-7b3c-4d21-f062-4c22b968b0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR0ATiKBk6rG",
        "colab_type": "text"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfzzfiDSuxMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "fileName = 'RML2016.10a_dict.pkl'\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/\"+fileName,'rb') as f:\n",
        "  data = pickle.load(f,encoding='bytes')\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjAg9T-0uzyh",
        "colab_type": "code",
        "outputId": "df3db3a6-8188-4d92-c787-60a371a4ca49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "X = []\n",
        "labels = [] # label each example by a pair (modulation type, snr)\n",
        "total_examples = 0\n",
        "analog = [b'AM-DSB', b'AM-SSB', b'WBFM']\n",
        "\n",
        "for mod_type, snr in data.keys():\n",
        "    if (mod_type not in analog):      \n",
        "        current_matrix = data[(mod_type, snr)]        \n",
        "        total_examples += current_matrix.shape[0]\n",
        "        for i in range(current_matrix.shape[0]):\n",
        "            X.append(current_matrix[i])\n",
        "            labels.append((str(mod_type, 'ascii'), snr)) # mod_type is of type bytes\n",
        "    \n",
        "X = np.array(X)         # First row is QPSK snr=2, seconde is PAM4 snr=8 , ...\n",
        "labels = np.array(labels)\n",
        "\n",
        "y = labels[:,0]\n",
        "\n",
        "print(f'loaded {total_examples} signal vectors into X{X.shape} and their corresponding'\n",
        "      f' labels into labels{labels.shape}')  \n",
        "# print(np.unique(labels[:,0]))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded 160000 signal vectors into X(160000, 2, 128) and their corresponding labels into labels(160000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbeDr3FVv57v",
        "colab_type": "code",
        "outputId": "0f48178e-dcb9-4a06-b2fa-55716b486c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)\n",
        "onehotencoder = OneHotEncoder()\n",
        "y = onehotencoder.fit_transform(y.reshape(-1,1)).toarray()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6iUKbJwKlT",
        "colab_type": "code",
        "outputId": "5cfe16fa-bd31-4214-f719-785985b3374e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "snrList = [str(2*i-20) for i in range(20)]  # snrList = -20, -18, -16 , ... ,0, ... ,18\n",
        "snr = snrList[19]\n",
        "numberOfEachExamples = 1000\n",
        "print(\"SNR :\", snr)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR : 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DiHGfSPwKb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.reshape([X.shape[0],256])\n",
        "output = [[labels[i*numberOfEachExamples, 0],y[i*numberOfEachExamples]] for i in range(int(X.shape[0]/numberOfEachExamples))]\n",
        "output = dict(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OJ3GghKwrbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_snr = []\n",
        "y_snr = []\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "    if labels[i,1] == snr:\n",
        "        X_snr.append(X[i])\n",
        "        y_snr.append(y[i])\n",
        "\n",
        "X_snr = np.array(X_snr)\n",
        "y_snr = np.array(y_snr)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx7l0G_3ww0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### Splitting the dataset into the Training set and Test set ######\n",
        "from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 0.2, random_state = 0)\n",
        "# The below line better for Cross_val part\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 1, random_state = 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujxapqcRw1l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWipMIzTw3SN",
        "colab_type": "text"
      },
      "source": [
        "# Making Simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t4bapTyw8Lp",
        "colab_type": "code",
        "outputId": "2f6931c7-6e30-4283-d72c-d8902a4e8ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "# Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))\n",
        "dout = 0.25\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(\"Model Created!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model Created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0K9N5wL2x3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 10\n",
        "epoch = 25\n",
        "classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch , validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNGu7HtyhGc2",
        "colab_type": "text"
      },
      "source": [
        "# Prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6irYYHCZ6A2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_real = np.argmax(y_test, axis=1)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_real, y_pred)\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "acc_test = classifier.evaluate(X_test, y_test)[1]\n",
        "acc_train = classifier.evaluate(X_train, y_train)[1]\n",
        "\n",
        "print(\"Acc Test : \", acc_test)\n",
        "print(\"Acc Train : \", acc_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seZ0vLFhjMOv",
        "colab_type": "text"
      },
      "source": [
        "#Cross_val(mean accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXeIQ_7HjTeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "def build_classifier():\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))    \n",
        "    dout = 0.1\n",
        "    classifier.add(Dropout(p = dout))\n",
        "    classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dropout(p = dout))\n",
        "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "batch = 10\n",
        "epoch = 25\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = batch, epochs = epoch)\n",
        "# It is better test_size = 1 in Splitting the dataset part\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = 1)\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-G3camZi47h",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy vs Droupout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC5FYw4Mi9mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "means = []\n",
        "for i in range(16):\n",
        "  def build_classifier():\n",
        "      classifier = Sequential()\n",
        "      classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))\n",
        "      dout = 0.05*i\n",
        "      classifier.add(Dropout(rate = dout))\n",
        "      classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "      classifier.add(Dropout(rate = dout))\n",
        "      classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "      classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "      return classifier\n",
        "\n",
        "  print(\"Dropout :\", 0.05*i)\n",
        "  batch = 10\n",
        "  epoch = 25\n",
        "  classifier = KerasClassifier(build_fn = build_classifier, batch_size = batch, epochs = epoch, verbose=0)\n",
        "  # It is better test_size = 1 in Splitting the dataset part\n",
        "  accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5, n_jobs = 1)\n",
        "  mean = accuracies.mean()\n",
        "  variance = accuracies.std()\n",
        "  print(mean)\n",
        "  means.append(mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EDsmrFQ6gUC",
        "colab_type": "code",
        "outputId": "9e2ecdc8-22b2-4efc-ee49-2157ddeef6cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = plt.plot(d, means, 'ro')\n",
        "plt.grid()\n",
        "plt.title('Accuracy vs Dropout for ANN (SNR=18)')\n",
        "plt.xlabel('Dropout', fontsize=8)\n",
        "plt.ylabel('Accuracy', fontsize=8)\n",
        "plt.ylim([0.30,0.5])\n",
        "plt.yticks(np.arange(0.3, 0.5, step=0.02))\n",
        "\n",
        "\n",
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "# fig = ax.get_figure()\n",
        "plt.savefig(dic+f\"/Pic/ANN-CrossVal(5)-132-132-ba{batch}-ep{epoch}(SNR={snr}).png\", dpi=175, bbox_inches='tight')\n",
        "plt.savefig(dic+f\"/Pic/ANN-CrossVal(5)-132-132-ba{batch}-ep{epoch}(SNR={snr}).eps\", bbox_inches='tight')\n",
        "\n",
        "print(\"Plot Saved!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Plot Saved!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEVCAYAAAD+TqKGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVsqJwszMSv1/gzyJsEUvjggAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z3gXo8JhU3Q",
        "colab_type": "text"
      },
      "source": [
        "# Iteration in Keras_val model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBsWXYtp4EWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer2_snr = []\n",
        "layer3_snr = []\n",
        "layer4_snr = []\n",
        "layer5_snr = []\n",
        "layer6_snr = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc3kPPYahdB5",
        "colab_type": "code",
        "outputId": "5d8a98d8-88f8-4a47-8e3c-5b3d763289df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for d in range(20):\n",
        "    snr = snrList[d]\n",
        "    print(\"layer2 \",snr)\n",
        "    \n",
        "    X_snr = []\n",
        "    y_snr = []\n",
        "    \n",
        "    for i in range(X.shape[0]):\n",
        "        if labels[i,1] == snr:\n",
        "            X_snr.append(X[i])\n",
        "            y_snr.append(y[i])\n",
        "    \n",
        "    X_snr = np.array(X_snr)\n",
        "    y_snr = np.array(y_snr)        \n",
        "    \n",
        "    ###### Splitting the dataset into the Training set and Test set ######\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 0.2, random_state = 0)\n",
        "    # The below line better for Cross_val part\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 1, random_state = 0)\n",
        "    \n",
        "    \n",
        "    # Feature Scaling\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "    X_test = sc.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # Evaluating the ANN\n",
        "    from keras.wrappers.scikit_learn import KerasClassifier\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "    \n",
        "    def build_classifier():\n",
        "        classifier = Sequential()\n",
        "        dout = 0.2\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))    \n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        return classifier\n",
        "    classifier = KerasClassifier(build_fn = build_classifier)\n",
        "    batch = 10\n",
        "    epoch = 25\n",
        "    classifier = KerasClassifier(build_fn = build_classifier, batch_size = batch, epochs = epoch, verbose=0)\n",
        "    # It is better test_size = 1 in Splitting the dataset part\n",
        "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 4, n_jobs = 1)\n",
        "    mean = accuracies.mean()\n",
        "    #variance = accuracies.std()\n",
        "   \n",
        "    layer2_snr.append(mean)\n",
        "    print(mean)\n",
        "    \n",
        "print(layer2_snr)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer2  -20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 15:53:59.253465 140641873090432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0730 15:53:59.269791 140641873090432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0730 15:53:59.274175 140641873090432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0730 15:53:59.293948 140641873090432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0730 15:53:59.304111 140641873090432 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0730 15:53:59.369996 140641873090432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0730 15:53:59.396325 140641873090432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0730 15:53:59.537258 140641873090432 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.12489076040034322\n",
            "layer2  -18\n",
            "0.12739257384528158\n",
            "layer2  -16\n",
            "0.1345170738121328\n",
            "layer2  -14\n",
            "0.15014420025704756\n",
            "layer2  -12\n",
            "0.20752582978023465\n",
            "layer2  -10\n",
            "0.2649089599224278\n",
            "layer2  -8\n",
            "0.3564198413424906\n",
            "layer2  -6\n",
            "0.4423055342168805\n",
            "layer2  -4\n",
            "0.5139379752755842\n",
            "layer2  -2\n",
            "0.5146907897803163\n",
            "layer2  0\n",
            "0.41467534404171125\n",
            "layer2  2\n",
            "0.4306783463397232\n",
            "layer2  4\n",
            "0.444177845674313\n",
            "layer2  6\n",
            "0.44318222300639154\n",
            "layer2  8\n",
            "0.43767822050047345\n",
            "layer2  10\n",
            "0.4430519698061917\n",
            "layer2  12\n",
            "0.43430715974300105\n",
            "layer2  14\n",
            "0.42892997136097744\n",
            "layer2  16\n",
            "0.4316777831801456\n",
            "layer2  18\n",
            "0.4411802220803449\n",
            "[0.12489076040034322, 0.12739257384528158, 0.1345170738121328, 0.15014420025704756, 0.20752582978023465, 0.2649089599224278, 0.3564198413424906, 0.4423055342168805, 0.5139379752755842, 0.5146907897803163, 0.41467534404171125, 0.4306783463397232, 0.444177845674313, 0.44318222300639154, 0.43767822050047345, 0.4430519698061917, 0.43430715974300105, 0.42892997136097744, 0.4316777831801456, 0.4411802220803449]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkAKeHXWl4sS",
        "colab_type": "code",
        "outputId": "9a11229e-ad27-4e37-9d34-4d3538996739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        }
      },
      "source": [
        "layer3_snr = [0.12839132328977573, 0.1280133217647569, 0.129141010790849, 0.14714313703179155, 0.19064914112870096, 0.2759097734660147]\n",
        "\n",
        "for d in range(14):\n",
        "    snr = snrList[d+6]\n",
        "    print(\"layer3 \",snr)\n",
        "    \n",
        "    X_snr = []\n",
        "    y_snr = []\n",
        "    \n",
        "    for i in range(X.shape[0]):\n",
        "        if labels[i,1] == snr:\n",
        "            X_snr.append(X[i])\n",
        "            y_snr.append(y[i])\n",
        "    \n",
        "    X_snr = np.array(X_snr)\n",
        "    y_snr = np.array(y_snr)        \n",
        "    \n",
        "    ###### Splitting the dataset into the Training set and Test set ######\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 0.2, random_state = 0)\n",
        "    # The below line better for Cross_val part\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 1, random_state = 0)\n",
        "    \n",
        "    \n",
        "    # Feature Scaling\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "    X_test = sc.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # Evaluating the ANN\n",
        "    from keras.wrappers.scikit_learn import KerasClassifier\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "    \n",
        "    def build_classifier():\n",
        "        classifier = Sequential()\n",
        "        dout = 0.2\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))    \n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        return classifier\n",
        "    classifier = KerasClassifier(build_fn = build_classifier)\n",
        "    batch = 10\n",
        "    epoch = 25\n",
        "    classifier = KerasClassifier(build_fn = build_classifier, batch_size = batch, epochs = epoch, verbose=0)\n",
        "    # It is better test_size = 1 in Splitting the dataset part\n",
        "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 4, n_jobs = 1)\n",
        "    mean = accuracies.mean()\n",
        "    #variance = accuracies.std()\n",
        "   \n",
        "    layer3_snr.append(mean)\n",
        "    print(mean)\n",
        "    \n",
        "print(layer3_snr)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer3  -8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 02:39:18.354471 140332317398912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0731 02:39:18.391252 140332317398912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0731 02:39:18.398953 140332317398912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0731 02:39:18.425853 140332317398912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0731 02:39:18.437837 140332317398912 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0731 02:39:18.537945 140332317398912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0731 02:39:18.568300 140332317398912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0731 02:39:18.730662 140332317398912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.3482970303279758\n",
            "layer3  -6\n",
            "0.4309272202443361\n",
            "layer3  -4\n",
            "0.5156864129550142\n",
            "layer3  -2\n",
            "0.49231247592676874\n",
            "layer3  0\n",
            "0.416302157891672\n",
            "layer3  2\n",
            "0.43942865825097\n",
            "layer3  4\n",
            "0.45430328348446997\n",
            "layer3  6\n",
            "0.46105853630153426\n",
            "layer3  8\n",
            "0.44367909604618294\n",
            "layer3  10\n",
            "0.44330272001746845\n",
            "layer3  12\n",
            "0.45493140986521896\n",
            "layer3  14\n",
            "0.4470553479792635\n",
            "layer3  16\n",
            "0.44692984663369345\n",
            "layer3  18\n",
            "0.45380678479010894\n",
            "[0.12839132328977573, 0.1280133217647569, 0.129141010790849, 0.14714313703179155, 0.19064914112870096, 0.2759097734660147, 0.3482970303279758, 0.4309272202443361, 0.5156864129550142, 0.49231247592676874, 0.416302157891672, 0.43942865825097, 0.45430328348446997, 0.46105853630153426, 0.44367909604618294, 0.44330272001746845, 0.45493140986521896, 0.4470553479792635, 0.44692984663369345, 0.45380678479010894]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvPCQBmd2SBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "\n",
        "with open(dic+f\"/Pic/ANN-CrossVal(4)-132-132-ba{batch}-ep{epoch}(SNR=-20to18)-AccuracyVsSNR.data\", 'wb') as filehandle:\n",
        "    # store the data as binary data stream\n",
        "    pickle.dump(layer2_snr, filehandle)\n",
        "    \n",
        "with open(dic+f\"/Pic/ANN-CrossVal(4)-132-132-132-ba{batch}-ep{epoch}(SNR=-20to18)-AccuracyVsSNR.data\", 'wb') as filehandle:\n",
        "    # store the data as binary data stream\n",
        "    pickle.dump(layer3_snr, filehandle)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdz3aLi6BRoh",
        "colab_type": "code",
        "outputId": "eb4dc8e2-fa0a-4768-e076-b03abb3e9f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "source": [
        "\n",
        "for d in range(20):\n",
        "    snr = snrList[d]\n",
        "    print(\"layer4 \",snr)\n",
        "    \n",
        "    X_snr = []\n",
        "    y_snr = []\n",
        "    \n",
        "    for i in range(X.shape[0]):\n",
        "        if labels[i,1] == snr:\n",
        "            X_snr.append(X[i])\n",
        "            y_snr.append(y[i])\n",
        "    \n",
        "    X_snr = np.array(X_snr)\n",
        "    y_snr = np.array(y_snr)        \n",
        "    \n",
        "    ###### Splitting the dataset into the Training set and Test set ######\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 0.2, random_state = 0)\n",
        "    # The below line better for Cross_val part\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 1, random_state = 0)\n",
        "    \n",
        "    \n",
        "    # Feature Scaling\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "    X_test = sc.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # Evaluating the ANN\n",
        "    from keras.wrappers.scikit_learn import KerasClassifier\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "    \n",
        "    def build_classifier():\n",
        "        classifier = Sequential()\n",
        "        dout = 0.2\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))    \n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        return classifier\n",
        "    classifier = KerasClassifier(build_fn = build_classifier)\n",
        "    batch = 10\n",
        "    epoch = 25\n",
        "    classifier = KerasClassifier(build_fn = build_classifier, batch_size = batch, epochs = epoch, verbose=0)\n",
        "    # It is better test_size = 1 in Splitting the dataset part\n",
        "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 4, n_jobs = 1)\n",
        "    mean = accuracies.mean()\n",
        "    #variance = accuracies.std()\n",
        "   \n",
        "    layer4_snr.append(mean)\n",
        "    print(mean)\n",
        "    \n",
        "print(layer4_snr)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer4  -20\n",
            "0.12351788633116793\n",
            "layer4  -18\n",
            "0.12013913454551747\n",
            "layer4  -16\n",
            "0.1282668859016741\n",
            "layer4  -14\n",
            "0.13376694868162195\n",
            "layer4  -12\n",
            "0.19127345332202633\n",
            "layer4  -10\n",
            "0.25528314706813515\n",
            "layer4  -8\n",
            "0.3454194663197879\n",
            "layer4  -6\n",
            "0.4405527833125705\n",
            "layer4  -4\n",
            "0.5199401008726665\n",
            "layer4  -2\n",
            "0.46806009894912004\n",
            "layer4  0\n",
            "0.43530203233933307\n",
            "layer4  2\n",
            "0.4391819723857322\n",
            "layer4  4\n",
            "0.4573043470170997\n",
            "layer4  6\n",
            "0.4614324730419912\n",
            "layer4  8\n",
            "0.4390564107892242\n",
            "layer4  10\n",
            "0.4456797834952968\n",
            "layer4  12\n",
            "0.4420585991299547\n",
            "layer4  14\n",
            "0.4436797836889327\n",
            "layer4  16\n",
            "0.44880403388569734\n",
            "layer4  18\n",
            "0.45930953624193793\n",
            "[0.12351788633116793, 0.12013913454551747, 0.1282668859016741, 0.13376694868162195, 0.19127345332202633, 0.25528314706813515, 0.3454194663197879, 0.4405527833125705, 0.5199401008726665, 0.46806009894912004, 0.43530203233933307, 0.4391819723857322, 0.4573043470170997, 0.4614324730419912, 0.4390564107892242, 0.4456797834952968, 0.4420585991299547, 0.4436797836889327, 0.44880403388569734, 0.45930953624193793]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWZvROCRg4AY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(dic+f\"/Pic/ANN-CrossVal(4)-132-132-132-132-ba{batch}-ep{epoch}(SNR=-20to18)-AccuracyVsSNR.data\", 'wb') as filehandle:\n",
        "    # store the data as binary data stream\n",
        "    pickle.dump(layer4_snr, filehandle)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFDsqgsbdega",
        "colab_type": "code",
        "outputId": "5fddb4b7-9992-40df-8486-59b402f20145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "\n",
        "for d in range(20):\n",
        "    snr = snrList[d]\n",
        "    print(\"layer5 \",snr)\n",
        "    \n",
        "    X_snr = []\n",
        "    y_snr = []\n",
        "    \n",
        "    for i in range(X.shape[0]):\n",
        "        if labels[i,1] == snr:\n",
        "            X_snr.append(X[i])\n",
        "            y_snr.append(y[i])\n",
        "    \n",
        "    X_snr = np.array(X_snr)\n",
        "    y_snr = np.array(y_snr)        \n",
        "    \n",
        "    ###### Splitting the dataset into the Training set and Test set ######\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 0.2, random_state = 0)\n",
        "    # The below line better for Cross_val part\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 1, random_state = 0)\n",
        "    \n",
        "    \n",
        "    # Feature Scaling\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "    X_test = sc.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # Evaluating the ANN\n",
        "    from keras.wrappers.scikit_learn import KerasClassifier\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "    \n",
        "    def build_classifier():\n",
        "        classifier = Sequential()\n",
        "        dout = 0.2\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))    \n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        return classifier\n",
        "    classifier = KerasClassifier(build_fn = build_classifier)\n",
        "    batch = 10\n",
        "    epoch = 25\n",
        "    classifier = KerasClassifier(build_fn = build_classifier, batch_size = batch, epochs = epoch, verbose=0)\n",
        "    # It is better test_size = 1 in Splitting the dataset part\n",
        "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 4, n_jobs = 1)\n",
        "    mean = accuracies.mean()\n",
        "    #variance = accuracies.std()\n",
        "   \n",
        "    layer5_snr.append(mean)\n",
        "    print(mean)\n",
        "    \n",
        "print(layer5_snr)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer5  -20\n",
            "0.12364013511655836\n",
            "layer5  -18\n",
            "0.1218885717240198\n",
            "layer5  -16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORPI905hhNfE",
        "colab_type": "text"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrHIolb35V1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tuning the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "def build_classifier(optimizer, n1, d):\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = n1, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))    \n",
        "    dout = d\n",
        "    classifier.add(Dropout(p = dout))\n",
        "    classifier.add(Dense(units = n1, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dropout(p = dout))\n",
        "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "    classifier.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "parameters = {'batch_size': [10, 25, 50, 75, 100],\n",
        "              'epochs': [10, 20, 50, 100],\n",
        "              'optimizer': ['adam', 'rmsprop'],\n",
        "              'n1':[66, 99, 165, 198, 231, 264, 297 ,396],\n",
        "              'n2':[66, 99, 165, 198, 231, 264, 297 ,396]}\n",
        "\n",
        "parameters = {'n1':[66, 99, 165, 198, 231, 264, 297 ,396],\n",
        "              'd':[0.1, 0.2, 0.3, 0.4, 0.5]}\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 2)\n",
        "\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "best_parameters = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "print('best_parameters : ', best_parameters)\n",
        "print('best_accuracy : ', best_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShXqOJL47hCE",
        "colab_type": "text"
      },
      "source": [
        "# Plot Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJdL7PP_7jir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "modulation_order = []\n",
        "modulation_order_dict = dict()\n",
        "\n",
        "for key,value in output.items():\n",
        "    modulation_order_dict[np.argmax(value)] = str(key)\n",
        "    \n",
        "for i in range(8):\n",
        "    modulation_order.append(modulation_order_dict[i])\n",
        "    \n",
        "    \n",
        "    \n",
        "cmDataFrame = pd.DataFrame(cm_norm, index=modulation_order, columns = modulation_order)\n",
        "plt.figure(figsize=(6, 5))\n",
        "ax = sns.heatmap(cmDataFrame, annot=True, annot_kws={\"size\": 8}, fmt='.2f', linewidths=.5, cmap=\"Greens\")\n",
        "\n",
        "plt.title(f\"AANN Confusion Matrix (SNR={snr})\")\n",
        "plt.xlabel(\"Predicted label  \\n\\n TrainAcc={:.2}, TestAcc={:.2}\".format(acc_train,acc_test), fontsize=8)\n",
        "plt.ylabel(\"True lable\", fontsize=8)\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\", fontsize=8)\n",
        "plt.setp(ax.get_yticklabels(), fontsize=8)\n",
        "fig = ax.get_figure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8eHSHvA7_ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "fig.savefig(dic+f\"ANN2-CrossVal-132-132-ba{batch}-ep{epoch}(SNR={snr}).png\", dpi=175, bbox_inches='tight')\n",
        "print(\"Plot Saved!\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}