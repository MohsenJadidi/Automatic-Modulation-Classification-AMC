{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohsenJadidi/Automatic-Modulation-Classification-AMC/blob/master/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0dBrWRWh7UO",
        "colab_type": "code",
        "outputId": "4d717c97-6281-4a2a-eb37-3da3ac293f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR0ATiKBk6rG",
        "colab_type": "text"
      },
      "source": [
        "# Importing the dataset (Copy from CNN.ipynb and merge cells)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfzzfiDSuxMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "cf328706-5d93-483b-da39-71c712c11fc0"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "fileName = 'RML2016.10a_dict.pkl'\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/\"+fileName,'rb') as f:\n",
        "  data = pickle.load(f,encoding='bytes')\n",
        " \n",
        "X = []\n",
        "labels = [] # label each example by a pair (modulation type, snr)\n",
        "total_examples = 0\n",
        "analog = [b'AM-DSB', b'AM-SSB', b'WBFM']\n",
        "\n",
        "for mod_type, snr in data.keys():\n",
        "    if (mod_type not in analog):      \n",
        "        current_matrix = data[(mod_type, snr)]        \n",
        "        total_examples += current_matrix.shape[0]\n",
        "        for i in range(current_matrix.shape[0]):\n",
        "            X.append(current_matrix[i])\n",
        "            labels.append((str(mod_type, 'ascii'), snr)) # mod_type is of type bytes\n",
        "    \n",
        "X = np.array(X)         # First row is QPSK snr=2, seconde is PAM4 snr=8 , ...\n",
        "labels = np.array(labels)\n",
        "\n",
        "y = labels[:,0]\n",
        "\n",
        "print(f'loaded {total_examples} signal vectors into X{X.shape} and their corresponding'\n",
        "      f' labels into labels{labels.shape}')  \n",
        "# print(np.unique(labels[:,0]))\n",
        "\n",
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)\n",
        "onehotencoder = OneHotEncoder()\n",
        "y = onehotencoder.fit_transform(y.reshape(-1,1)).toarray()\n",
        "\n",
        "snrList = [str(2*i-20) for i in range(20)]  # snrList = -20, -18, -16 , ... ,0, ... ,18\n",
        "snr = snrList[19]\n",
        "numberOfEachExamples = 1000\n",
        "print(\"SNR :\", snr)\n",
        "\n",
        "output = [[labels[i*numberOfEachExamples, 0],y[i*numberOfEachExamples]] for i in range(int(X.shape[0]/numberOfEachExamples))]\n",
        "output = dict(output)\n",
        "\n",
        "X_snr = []\n",
        "y_snr = []\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "    if labels[i,1] == snr:\n",
        "        X_snr.append(X[i])\n",
        "        y_snr.append(y[i])\n",
        "\n",
        "X_snr = np.array(X_snr)\n",
        "y_snr = np.array(y_snr)  \n",
        "\n",
        "###### Splitting the dataset into the Training set and Test set ######\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 0.2, random_state = 0)\n",
        "# The below line better for Cross_val part\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 1, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "# StandardScaler expected <= 2.\n",
        "#X_train = X_train.reshape([6400,256])\n",
        "X_train = X_train.reshape([X_train.shape[0],256])\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_train = X_train.reshape([X_train.shape[0],2,128])\n",
        "#X_test = X_test.reshape([1600,256])\n",
        "X_test = X_test.reshape([X_test.shape[0],256])\n",
        "X_test = sc.transform(X_test)\n",
        "X_test = X_test.reshape([X_test.shape[0],2,128])\n",
        "\n",
        "# Reshape\n",
        "X_train = X_train.reshape(-1,2, 128, 1)   #Reshape for CNN -  (6400,2,128)->(6400,2,128,1)!!\n",
        "X_test = X_test.reshape(-1,2, 128, 1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded 160000 signal vectors into X(160000, 2, 128) and their corresponding labels into labels(160000, 2)\n",
            "SNR : 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drh0_kLlLXWK",
        "colab_type": "text"
      },
      "source": [
        "## Import Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9wXGX95LU7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAqdPV-N3Ae_",
        "colab_type": "text"
      },
      "source": [
        "#Making ResNet0 model (four-convolutional-layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPoNtK--g3Fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "566e83a4-54cc-4c91-8588-5ab73e09978e"
      },
      "source": [
        "dout = 0.4\n",
        "\n",
        "modelInput = Input(shape=(2,128,1))\n",
        "\n",
        "x1 = ZeroPadding2D((0, 2)) (modelInput)\n",
        "x1 = Conv2D(256,1,3, activation = 'relu')(x1)\n",
        "x1 = Dropout(rate=dout)(x1)\n",
        "\n",
        "x2 = Conv2D(256,2,3, activation = 'relu')(x1)\n",
        "x2 = Dropout(rate=dout)(x2)\n",
        "\n",
        "skip1 = add([x2,modelInput])\n",
        "\n",
        "x3 = Conv2D(80,1,3, activation = 'relu')(skip1)\n",
        "x3 = Dropout(rate=dout)(x3)\n",
        "\n",
        "x4 = Conv2D(80,1,3, activation = 'relu')(x3)\n",
        "x4 = Dropout(rate=dout)(x4)\n",
        "\n",
        "x5 = Flatten()(x4)\n",
        "\n",
        "x6 = Dense(output_dim = 128 , activation = 'relu')(x5)\n",
        "x6 = Dropout(rate=dout)(x6)\n",
        "\n",
        "out = Dense(output_dim = 8 , activation = 'softmax')(x6)\n",
        "\n",
        "classifier = Model(inputs = modelInput, outputs = out)\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "print(\"Model Created!\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (2, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(80, (1, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(80, (1, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=8)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 2, 128, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 2, 132, 1)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 2, 130, 256)  1024        zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 2, 130, 256)  0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 1, 128, 256)  393472      dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 1, 128, 256)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 2, 128, 256)  0           dropout_8[0][0]                  \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 2, 126, 80)   61520       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 2, 126, 80)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 2, 124, 80)   19280       dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 2, 124, 80)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 19840)        0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          2539648     flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 128)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 8)            1032        dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 3,015,976\n",
            "Trainable params: 3,015,976\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model Created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSbYplCLLPbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "outputId": "72b6b042-26b2-4306-b6d1-3334df8fafe1"
      },
      "source": [
        "from keras.layers.core import Reshape\n",
        "from keras.layers.convolutional import Conv2D, ZeroPadding2D\n",
        "from keras.layers import Concatenate,Input,add\n",
        "\n",
        "in_shp = list(X_train.shape[1:])\n",
        "dr = 0.5\n",
        "\n",
        "\n",
        "model = Sequential()  # 这里使用keras的序贯模型  https://keras-cn.readthedocs.io/en/latest/models/sequential/\n",
        "# Reshape [N,2,128] to [N,1,2,128] on input\n",
        "input_x = Input(shape=(2, 128)) \n",
        "\n",
        "model0=(Reshape(([1] + in_shp), input_shape=in_shp))(input_x)\n",
        "model0=(ZeroPadding2D((0, 2), data_format=\"channels_first\"))(model0)\n",
        "print(model0)\n",
        "# 卷积核维度(输出尺度),卷积核的宽度和长度,“valid”代表只进行有效的卷积，即对边界数据不处理,\n",
        "# 层权重weights的初始化函数\n",
        "# channels_first corresponds to inputs with shape (batch, channels, height, width).\n",
        "\n",
        "model1=(Conv2D(256, (1, 3), padding='same', activation=\"relu\", name=\"conv1\", init='glorot_uniform',\n",
        "                 data_format=\"channels_first\"))(model0)\n",
        "model1=(Dropout(dr))(model1)\n",
        "#model1=(ZeroPadding2D((0, 2), data_format=\"channels_first\"))(model1)\n",
        "\n",
        "model2=(Conv2D(256, (2, 3), padding=\"same\", activation=\"relu\", name=\"conv2\", init='glorot_uniform',\n",
        "                 data_format=\"channels_first\"))(model1)\n",
        "#model2=(ZeroPadding2D((0, 2), data_format=\"channels_first\"))(model2)\n",
        "modela = add([model1, model2])\n",
        "model3=(Conv2D(80, (1, 3), padding='same', activation=\"relu\", name=\"conv3\", init='glorot_uniform',\n",
        "                 data_format=\"channels_first\"))(modela)\n",
        "#model3=(ZeroPadding2D((0, 2), data_format=\"channels_first\"))(model3)\n",
        "\n",
        "#model3=(Dropout(dr))(model3)\n",
        "model4 = Concatenate(axis = 1)([model1, model2,model3])\n",
        "\n",
        "model4=(Conv2D(80, (1, 3), padding='valid', activation=\"relu\", name=\"conv4\", init='glorot_uniform',\n",
        "                 data_format=\"channels_first\"))(model4)\n",
        "# 多维的输入一维化，常用在从卷积层到全连接层的过渡\n",
        "\n",
        "x = (Flatten())(model4)\n",
        "x=(Dense(128, activation='relu',  name=\"dense1\"))(x)\n",
        "x=(Dropout(dr))(x)\n",
        "x=(Dense(8, activation = 'softmax' ,name=\"dense2\"))(x)\n",
        "\n",
        "x=(Reshape([8]))(x)\n",
        "model = Model(inputs=input_x, outputs=x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Set up some params\n",
        "epochs = 25  # number of epochs to train on\n",
        "batch_size = 64  # training batch size default1024\n",
        "\n",
        "#model.load_weights('dense.h5')\n",
        "\n",
        "filepath = \"dense.h5\"   # 所要保存的文件名字，h5格式，不用写路径，默认在程序执行的文件夹内\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1699 - acc: 0.9231 - val_loss: 0.6225 - val_acc: 0.7944\n",
            "Epoch 2/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1650 - acc: 0.9267 - val_loss: 0.5979 - val_acc: 0.7994\n",
            "Epoch 3/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1651 - acc: 0.9281 - val_loss: 0.6374 - val_acc: 0.8025\n",
            "Epoch 4/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1550 - acc: 0.9295 - val_loss: 0.6222 - val_acc: 0.7987\n",
            "Epoch 5/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1560 - acc: 0.9294 - val_loss: 0.6052 - val_acc: 0.7913\n",
            "Epoch 6/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1653 - acc: 0.9250 - val_loss: 0.6614 - val_acc: 0.7812\n",
            "Epoch 7/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1502 - acc: 0.9338 - val_loss: 0.6753 - val_acc: 0.7831\n",
            "Epoch 8/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1486 - acc: 0.9363 - val_loss: 0.6927 - val_acc: 0.8013\n",
            "Epoch 9/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1417 - acc: 0.9402 - val_loss: 0.6424 - val_acc: 0.7950\n",
            "Epoch 10/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1451 - acc: 0.9347 - val_loss: 0.7397 - val_acc: 0.7881\n",
            "Epoch 11/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1344 - acc: 0.9384 - val_loss: 0.6628 - val_acc: 0.7863\n",
            "Epoch 12/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1361 - acc: 0.9392 - val_loss: 0.6616 - val_acc: 0.7919\n",
            "Epoch 13/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1296 - acc: 0.9405 - val_loss: 0.8107 - val_acc: 0.7831\n",
            "Epoch 14/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1421 - acc: 0.9363 - val_loss: 0.6688 - val_acc: 0.7900\n",
            "Epoch 15/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1532 - acc: 0.9375 - val_loss: 0.8143 - val_acc: 0.7775\n",
            "Epoch 16/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1339 - acc: 0.9406 - val_loss: 0.6378 - val_acc: 0.7919\n",
            "Epoch 17/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1250 - acc: 0.9414 - val_loss: 0.6968 - val_acc: 0.7887\n",
            "Epoch 18/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1346 - acc: 0.9403 - val_loss: 0.7330 - val_acc: 0.7863\n",
            "Epoch 19/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1523 - acc: 0.9330 - val_loss: 0.7327 - val_acc: 0.7887\n",
            "Epoch 20/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1389 - acc: 0.9425 - val_loss: 0.8057 - val_acc: 0.7937\n",
            "Epoch 21/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1363 - acc: 0.9420 - val_loss: 0.7790 - val_acc: 0.7875\n",
            "Epoch 22/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1417 - acc: 0.9403 - val_loss: 0.7376 - val_acc: 0.7906\n",
            "Epoch 23/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1308 - acc: 0.9453 - val_loss: 0.7455 - val_acc: 0.7931\n",
            "Epoch 24/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1132 - acc: 0.9497 - val_loss: 0.8685 - val_acc: 0.7925\n",
            "Epoch 25/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 0.1212 - acc: 0.9486 - val_loss: 0.7871 - val_acc: 0.7881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct6SfO0K3RPR",
        "colab_type": "text"
      },
      "source": [
        "# Fitting model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txz8QArgZaQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "42d2cc93-a76c-4a0a-d29c-830b3fba1791"
      },
      "source": [
        "batch = 16\n",
        "epoch = 25\n",
        "#history = classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch, validation_data=(X_test, y_test))\n",
        "history = classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "6400/6400 [==============================] - 8s 1ms/step - loss: 1.9819 - acc: 0.2008\n",
            "Epoch 2/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 1.8493 - acc: 0.2289\n",
            "Epoch 3/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 1.7924 - acc: 0.2397\n",
            "Epoch 4/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 1.7401 - acc: 0.2497\n",
            "Epoch 5/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 1.7141 - acc: 0.2539\n",
            "Epoch 6/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 1.7116 - acc: 0.2564\n",
            "Epoch 7/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 1.6949 - acc: 0.2728\n",
            "Epoch 8/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 1.6667 - acc: 0.2689\n",
            "Epoch 9/25\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 1.6620 - acc: 0.2884\n",
            "Epoch 10/25\n",
            "3760/6400 [================>.............] - ETA: 2s - loss: 1.6285 - acc: 0.3199"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}