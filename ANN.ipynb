{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohsenJadidi/Automatic-Modulation-Classification-AMC/blob/master/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbWAylFFl7H3",
        "colab_type": "code",
        "outputId": "28d4d872-eb82-4a98-fb53-3ad333518f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR0ATiKBk6rG",
        "colab_type": "text"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfzzfiDSuxMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "fileName = 'RML2016.10a_dict.pkl'\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/\"+fileName,'rb') as f:\n",
        "  data = pickle.load(f,encoding='bytes')\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjAg9T-0uzyh",
        "colab_type": "code",
        "outputId": "b8839f33-72be-4dd8-f724-b7c643e7aa5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "X = []\n",
        "labels = [] # label each example by a pair (modulation type, snr)\n",
        "total_examples = 0\n",
        "analog = [b'AM-DSB', b'AM-SSB', b'WBFM']\n",
        "\n",
        "for mod_type, snr in data.keys():\n",
        "    if (mod_type not in analog):      \n",
        "        current_matrix = data[(mod_type, snr)]        \n",
        "        total_examples += current_matrix.shape[0]\n",
        "        for i in range(current_matrix.shape[0]):\n",
        "            X.append(current_matrix[i])\n",
        "            labels.append((str(mod_type, 'ascii'), snr)) # mod_type is of type bytes\n",
        "    \n",
        "X = np.array(X)         # First row is QPSK snr=2, seconde is PAM4 snr=8 , ...\n",
        "labels = np.array(labels)\n",
        "\n",
        "y = labels[:,0]\n",
        "\n",
        "print(f'loaded {total_examples} signal vectors into X{X.shape} and their corresponding'\n",
        "      f' labels into labels{labels.shape}')  \n",
        "# print(np.unique(labels[:,0]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded 160000 signal vectors into X(160000, 2, 128) and their corresponding labels into labels(160000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbeDr3FVv57v",
        "colab_type": "code",
        "outputId": "e05964e5-c211-469f-907b-f6d9e7b7d64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)\n",
        "onehotencoder = OneHotEncoder()\n",
        "y = onehotencoder.fit_transform(y.reshape(-1,1)).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6iUKbJwKlT",
        "colab_type": "code",
        "outputId": "a9542b6c-19e4-4c44-8d40-26b249969128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "snrList = [str(2*i-20) for i in range(20)]  # snrList = -20, -18, -16 , ... ,0, ... ,18\n",
        "snr = snrList[19]\n",
        "numberOfEachExamples = 1000\n",
        "print(\"SNR :\", snrList)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR : ['-20', '-18', '-16', '-14', '-12', '-10', '-8', '-6', '-4', '-2', '0', '2', '4', '6', '8', '10', '12', '14', '16', '18']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DiHGfSPwKb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = [[labels[i*numberOfEachExamples, 0],y[i*numberOfEachExamples]] for i in range(int(X.shape[0]/numberOfEachExamples))]\n",
        "output = dict(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OJ3GghKwrbs",
        "colab_type": "code",
        "outputId": "05c78d6f-1522-48b1-91f9-a24343396c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xsnr = np.zeros(shape=(X.shape[0],X.shape[1],X.shape[2]+1))\n",
        "for i in range(X.shape[0]):\n",
        "    snr = int(labels[i,1])\n",
        "    Xsnr[i,0,:] = np.insert(X[i,0,:],0,snr)\n",
        "    Xsnr[i,1,:] = np.insert(X[i,1,:],0,snr)\n",
        "    \n",
        "print(Xsnr.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 2, 129)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx7l0G_3ww0w",
        "colab_type": "code",
        "outputId": "3d68df1f-5784-4dfc-b2dc-3c6531d7208c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "###### Splitting the dataset into the Training set and Test set ######\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xsnr, y, test_size = 0.2, random_state = 0)\n",
        "# The below line better for Cross_val part\n",
        "#X_train, X_test, y_train, y_test = train_test_split(Xsnr, y, test_size = 1, random_state = 0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128000, 2, 129)\n",
            "(32000, 2, 129)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGeDKe8GLNJ9",
        "colab_type": "code",
        "outputId": "e1c3835c-8a55-49d7-ee98-aeb33c199d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X_train = X_train[:,:,1:] # snr important for train\n",
        "\n",
        "y_test18 = []\n",
        "X_test18 = []\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    if X_test[i,0,0] == 18:\n",
        "        X_test18.append(X_test[i])\n",
        "        y_test18.append(y_test[i])\n",
        "        \n",
        "X_test18 = np.array(X_test18)\n",
        "y_test18 = np.array(y_test18)        \n",
        "X_test18 = X_test18[:,:,1:]\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test18.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128000, 2, 128)\n",
            "(1653, 2, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4OinfCHLd8y",
        "colab_type": "code",
        "outputId": "153c0273-c35a-442f-b616-a827f9b5d08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Change IQ to amplitude and phase\n",
        "X_cmplx = X_train[:,0,:] + 1j* X_train[:,1,:]    \n",
        "X_amp = np.abs(X_cmplx)\n",
        "X_ang = np.arctan2(X_train[:,1,:],X_train[:,0,:]) / np.pi\n",
        "    \n",
        "X_amp = np.reshape(X_amp,(-1,1,128))\n",
        "X_ang = np.reshape(X_ang,(-1,1,128))\n",
        "    \n",
        "X_train_AmpPhs = np.concatenate((X_amp,X_ang), axis=1) \n",
        "##\n",
        "X_cmplx = X_test18[:,0,:] + 1j* X_test18[:,1,:]    \n",
        "X_amp = np.abs(X_cmplx)\n",
        "X_ang = np.arctan2(X_test18[:,1,:],X_test18[:,0,:]) / np.pi\n",
        "    \n",
        "X_amp = np.reshape(X_amp,(-1,1,128))\n",
        "X_ang = np.reshape(X_ang,(-1,1,128))\n",
        "    \n",
        "X_test18_AmpPhs = np.concatenate((X_amp,X_ang), axis=1) \n",
        "##\n",
        "\n",
        "print(X_train_AmpPhs.shape)\n",
        "print(X_test18_AmpPhs.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128000, 2, 128)\n",
            "(1653, 2, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuKWgf69MhKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = X_train.reshape([X_train.shape[0],256])\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_train = X_train.reshape([X_train.shape[0],2,128])\n",
        "#X_test = X_test.reshape([1600,256])\n",
        "X_test18 = X_test18.reshape([X_test18.shape[0],256])\n",
        "X_test18 = sc.transform(X_test18)\n",
        "X_test18 = X_test18.reshape([X_test18.shape[0],2,128])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGTuYsrYNnWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape([X_train.shape[0],256])\n",
        "X_test18 = X_test18.reshape([X_test18.shape[0],256])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWipMIzTw3SN",
        "colab_type": "text"
      },
      "source": [
        "# Making Simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t4bapTyw8Lp",
        "colab_type": "code",
        "outputId": "d781cc57-c997-4c31-b9d7-d6733ac4ac2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "# Initialising the ANN\n",
        "\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))\n",
        "dout = 0.2\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "#classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "#classifier.add(Dropout(rate = dout))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#logger = keras.callbacks.TensorBoard(log_dir=\"./logs\", write_graph=True, histogram_freq=0)\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "print(\"Model Created!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 132)               33924     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 132)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 132)               17556     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 132)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 132)               17556     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 132)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 132)               17556     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 132)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 8)                 1064      \n",
            "=================================================================\n",
            "Total params: 87,656\n",
            "Trainable params: 87,656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0K9N5wL2x3F",
        "colab_type": "code",
        "outputId": "d0e70229-1562-40df-de92-4f3186cf04ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "batch = 1024\n",
        "epoch = 25\n",
        "\n",
        "history = classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch, validation_data=(X_test18, y_test18))\n",
        "#history = classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 128000 samples, validate on 1653 samples\n",
            "Epoch 1/25\n",
            "128000/128000 [==============================] - 11s 88us/step - loss: 1.3907 - acc: 0.3998 - val_loss: 0.9772 - val_acc: 0.5493\n",
            "Epoch 2/25\n",
            "128000/128000 [==============================] - 11s 88us/step - loss: 1.3902 - acc: 0.4008 - val_loss: 0.9809 - val_acc: 0.5566\n",
            "Epoch 3/25\n",
            "128000/128000 [==============================] - 12s 92us/step - loss: 1.3878 - acc: 0.4011 - val_loss: 0.9827 - val_acc: 0.5414\n",
            "Epoch 4/25\n",
            "128000/128000 [==============================] - 12s 92us/step - loss: 1.3838 - acc: 0.4017 - val_loss: 0.9676 - val_acc: 0.5293\n",
            "Epoch 5/25\n",
            "128000/128000 [==============================] - 12s 91us/step - loss: 1.3841 - acc: 0.4050 - val_loss: 0.9632 - val_acc: 0.5457\n",
            "Epoch 6/25\n",
            "128000/128000 [==============================] - 12s 94us/step - loss: 1.3820 - acc: 0.4048 - val_loss: 0.9959 - val_acc: 0.5203\n",
            "Epoch 7/25\n",
            "128000/128000 [==============================] - 12s 93us/step - loss: 1.3796 - acc: 0.4052 - val_loss: 0.9927 - val_acc: 0.5318\n",
            "Epoch 8/25\n",
            "128000/128000 [==============================] - 12s 95us/step - loss: 1.3746 - acc: 0.4064 - val_loss: 0.9783 - val_acc: 0.5445\n",
            "Epoch 9/25\n",
            "128000/128000 [==============================] - 12s 96us/step - loss: 1.3757 - acc: 0.4079 - val_loss: 0.9551 - val_acc: 0.5699\n",
            "Epoch 10/25\n",
            "128000/128000 [==============================] - 12s 91us/step - loss: 1.3735 - acc: 0.4068 - val_loss: 0.9664 - val_acc: 0.5481\n",
            "Epoch 11/25\n",
            "128000/128000 [==============================] - 12s 93us/step - loss: 1.3678 - acc: 0.4098 - val_loss: 0.9663 - val_acc: 0.5517\n",
            "Epoch 12/25\n",
            "128000/128000 [==============================] - 12s 92us/step - loss: 1.3713 - acc: 0.4092 - val_loss: 0.9864 - val_acc: 0.4979\n",
            "Epoch 13/25\n",
            "128000/128000 [==============================] - 12s 94us/step - loss: 1.3662 - acc: 0.4120 - val_loss: 0.9636 - val_acc: 0.5463\n",
            "Epoch 14/25\n",
            "128000/128000 [==============================] - 12s 95us/step - loss: 1.3684 - acc: 0.4121 - val_loss: 0.9641 - val_acc: 0.5535\n",
            "Epoch 15/25\n",
            "128000/128000 [==============================] - 12s 96us/step - loss: 1.3630 - acc: 0.4128 - val_loss: 0.9516 - val_acc: 0.5620\n",
            "Epoch 16/25\n",
            "128000/128000 [==============================] - 12s 95us/step - loss: 1.3614 - acc: 0.4144 - val_loss: 0.9411 - val_acc: 0.5578\n",
            "Epoch 17/25\n",
            "128000/128000 [==============================] - 12s 95us/step - loss: 1.3612 - acc: 0.4148 - val_loss: 0.9487 - val_acc: 0.5644\n",
            "Epoch 18/25\n",
            "128000/128000 [==============================] - 12s 97us/step - loss: 1.3587 - acc: 0.4150 - val_loss: 0.9358 - val_acc: 0.5789\n",
            "Epoch 19/25\n",
            "128000/128000 [==============================] - 12s 92us/step - loss: 1.3572 - acc: 0.4156 - val_loss: 0.9585 - val_acc: 0.5451\n",
            "Epoch 20/25\n",
            "128000/128000 [==============================] - 12s 93us/step - loss: 1.3562 - acc: 0.4183 - val_loss: 0.9398 - val_acc: 0.5735\n",
            "Epoch 21/25\n",
            "128000/128000 [==============================] - 12s 90us/step - loss: 1.3533 - acc: 0.4181 - val_loss: 0.9483 - val_acc: 0.5469\n",
            "Epoch 22/25\n",
            "128000/128000 [==============================] - 12s 91us/step - loss: 1.3516 - acc: 0.4180 - val_loss: 0.9491 - val_acc: 0.5771\n",
            "Epoch 23/25\n",
            "128000/128000 [==============================] - 11s 89us/step - loss: 1.3505 - acc: 0.4207 - val_loss: 0.9380 - val_acc: 0.5802\n",
            "Epoch 24/25\n",
            "128000/128000 [==============================] - 12s 95us/step - loss: 1.3470 - acc: 0.4221 - val_loss: 0.9269 - val_acc: 0.5753\n",
            "Epoch 25/25\n",
            "128000/128000 [==============================] - 12s 94us/step - loss: 1.3456 - acc: 0.4214 - val_loss: 0.9495 - val_acc: 0.5318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVFgwssVfxtd",
        "colab_type": "text"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKe0m_39HiWU",
        "colab_type": "code",
        "outputId": "6266484f-cb86-4a17-885b-36957d603a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "classifier.save(dic+f'SaveModel/ANN-ba{batch}-ep{epoch}(SNR=all).h5')\n",
        "print('Model Saved!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNGu7HtyhGc2",
        "colab_type": "text"
      },
      "source": [
        "# Prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6irYYHCZ6A2C",
        "colab_type": "code",
        "outputId": "c18f7754-ef06-47b5-cd97-8d8c59e1686c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "y_pred = classifier.predict(X_test18)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_real = np.argmax(y_test18, axis=1)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_real, y_pred)\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "acc_test = classifier.evaluate(X_test18, y_test18)[1]\n",
        "acc_train = classifier.evaluate(X_train, y_train)[1]\n",
        "\n",
        "print(\"Acc Test : \", acc_test)\n",
        "print(\"Acc Train : \", acc_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1653/1653 [==============================] - 0s 29us/step\n",
            "128000/128000 [==============================] - 4s 30us/step\n",
            "Acc Test :  0.5317604358601555\n",
            "Acc Train :  0.442328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seZ0vLFhjMOv",
        "colab_type": "text"
      },
      "source": [
        "#Cross_val(mean accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXeIQ_7HjTeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "def build_classifier():\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))    \n",
        "    dout = 0.1\n",
        "    classifier.add(Dropout(p = dout))\n",
        "    classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dropout(p = dout))\n",
        "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "batch = 10\n",
        "epoch = 25\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = batch, epochs = epoch)\n",
        "# It is better test_size = 1 in Splitting the dataset part\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5, n_jobs = 1)\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-G3camZi47h",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy vs Droupout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC5FYw4Mi9mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "means = []\n",
        "for i in range(16):\n",
        "  def build_classifier():\n",
        "      classifier = Sequential()\n",
        "      classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))\n",
        "      dout = 0.05*i\n",
        "      classifier.add(Dropout(rate = dout))\n",
        "      classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "      classifier.add(Dropout(rate = dout))\n",
        "      classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "      classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "      return classifier\n",
        "\n",
        "  print(\"Dropout :\", 0.05*i)\n",
        "  batch = 10\n",
        "  epoch = 25\n",
        "  classifier = KerasClassifier(build_fn = build_classifier, batch_size = batch, epochs = epoch, verbose=0)\n",
        "  # It is better test_size = 1 in Splitting the dataset part\n",
        "  accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5, n_jobs = 1)\n",
        "  mean = accuracies.mean()\n",
        "  variance = accuracies.std()\n",
        "  print(mean)\n",
        "  means.append(mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EDsmrFQ6gUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = plt.plot(d, means, 'ro')\n",
        "plt.grid()\n",
        "plt.title('Accuracy vs Dropout for ANN (SNR=18)')\n",
        "plt.xlabel('Dropout', fontsize=8)\n",
        "plt.ylabel('Accuracy', fontsize=8)\n",
        "plt.ylim([0.30,0.5])\n",
        "plt.yticks(np.arange(0.3, 0.5, step=0.02))\n",
        "\n",
        "\n",
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "# fig = ax.get_figure()\n",
        "plt.savefig(dic+f\"/Pic/ANN-CrossVal(5)-132-132-ba{batch}-ep{epoch}(SNR={snr}).png\", dpi=175, bbox_inches='tight')\n",
        "plt.savefig(dic+f\"/Pic/ANN-CrossVal(5)-132-132-ba{batch}-ep{epoch}(SNR={snr}).eps\", bbox_inches='tight')\n",
        "\n",
        "print(\"Plot Saved!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z3gXo8JhU3Q",
        "colab_type": "text"
      },
      "source": [
        "# Iteration in Keras_val model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBsWXYtp4EWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer2_snr = []\n",
        "layer3_snr = []\n",
        "layer4_snr = []\n",
        "layer5_snr = []\n",
        "layer6_snr = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc3kPPYahdB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for d in range(20):\n",
        "    snr = snrList[d]\n",
        "    print(\"layer2 \",snr)\n",
        "    \n",
        "    X_snr = []\n",
        "    y_snr = []\n",
        "    \n",
        "    for i in range(X.shape[0]):\n",
        "        if labels[i,1] == snr:\n",
        "            X_snr.append(X[i])\n",
        "            y_snr.append(y[i])\n",
        "    \n",
        "    X_snr = np.array(X_snr)\n",
        "    y_snr = np.array(y_snr)        \n",
        "    \n",
        "    ###### Splitting the dataset into the Training set and Test set ######\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 0.2, random_state = 0)\n",
        "    # The below line better for Cross_val part\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 1, random_state = 0)\n",
        "    \n",
        "    \n",
        "    # Feature Scaling\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "    X_test = sc.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # Evaluating the ANN\n",
        "    from keras.wrappers.scikit_learn import KerasClassifier\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "    \n",
        "    def build_classifier():\n",
        "        classifier = Sequential()\n",
        "        dout = 0.2\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))    \n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 132, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dropout(rate = dout))\n",
        "        classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        return classifier\n",
        "    classifier = KerasClassifier(build_fn = build_classifier)\n",
        "    batch = 10\n",
        "    epoch = 25\n",
        "    classifier = KerasClassifier(build_fn = build_classifier, batch_size = batch, epochs = epoch, verbose=0)\n",
        "    # It is better test_size = 1 in Splitting the dataset part\n",
        "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 4, n_jobs = 1)\n",
        "    mean = accuracies.mean()\n",
        "    #variance = accuracies.std()\n",
        "   \n",
        "    layer2_snr.append(mean)\n",
        "    print(mean)\n",
        "    \n",
        "print(layer2_snr)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOGsK1WlhdUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer2=[0.12489076040034322, 0.12739257384528158, 0.1345170738121328, 0.15014420025704756, 0.20752582978023465, 0.2649089599224278, 0.3564198413424906, 0.4423055342168805, 0.5139379752755842, 0.5146907897803163, 0.41467534404171125, 0.4306783463397232, 0.444177845674313, 0.44318222300639154, 0.43767822050047345, 0.4430519698061917, 0.43430715974300105, 0.42892997136097744, 0.4316777831801456, 0.4411802220803449]\n",
        "layer3=[0.12839132328977573, 0.1280133217647569, 0.129141010790849, 0.14714313703179155, 0.19064914112870096, 0.2759097734660147, 0.3482970303279758, 0.4309272202443361, 0.5156864129550142, 0.49231247592676874, 0.416302157891672, 0.43942865825097, 0.45430328348446997, 0.46105853630153426, 0.44367909604618294, 0.44330272001746845, 0.45493140986521896, 0.4470553479792635, 0.44692984663369345, 0.45380678479010894]\n",
        "layer4=[0.12351788633116793, 0.12013913454551747, 0.1282668859016741, 0.13376694868162195, 0.19127345332202633, 0.25528314706813515, 0.3454194663197879, 0.4405527833125705, 0.5199401008726665, 0.46806009894912004, 0.43530203233933307, 0.4391819723857322, 0.4573043470170997, 0.4614324730419912, 0.4390564107892242, 0.4456797834952968, 0.4420585991299547, 0.4436797836889327, 0.44880403388569734, 0.45930953624193793]\n",
        "layer6=[0.12176488498030133, 0.1206392595865971, 0.1263911355274071, 0.13051619836136702, 0.18102239030261916, 0.2550320215183932, 0.3325442786952327, 0.4048007819840751, 0.4590520329241515, 0.4101771581712262, 0.4276769702980111, 0.4348042838300544, 0.4451785335386672, 0.44567940908071846, 0.4253042841522818, 0.43630090747900746, 0.4334299094650546, 0.42992897172329886, 0.4370537209871219, 0.43930741033364473]\n",
        "layer5=[0.1215151350374048, 0.12564076038452518, 0.12901626068493513, 0.13426782412679977, 0.19539807813905047, 0.2656578972355545, 0.3444180280829418, 0.43130284556253384, 0.5000635384031715, 0.4233030332383206, 0.42655278284296494, 0.44280603514509964, 0.44980347093662476, 0.45055428394180286, 0.4396790965828064, 0.4369294086336464, 0.43793309848314865, 0.44367940879573653, 0.442431347613242, 0.4561860372124099]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORPI905hhNfE",
        "colab_type": "text"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrHIolb35V1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tuning the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "def build_classifier(n1):\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = n1, kernel_initializer = 'uniform', activation = 'relu', input_dim = 256))    \n",
        "    dout = 0.2\n",
        "    classifier.add(Dropout(p = dout))\n",
        "    classifier.add(Dense(units = n1, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dropout(p = dout))\n",
        "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "parameters = {'batch_size': [10, 25, 50, 75, 100],\n",
        "              'epochs': [10, 20, 50, 100],\n",
        "              'optimizer': ['adam', 'rmsprop'],\n",
        "              'n1':[66, 99, 165, 198, 231, 264, 297 ,396],\n",
        "              'n2':[66, 99, 165, 198, 231, 264, 297 ,396]}\n",
        "\n",
        "parameters = {'n1':[66, 99, 165, 198, 231, 264, 297 ,396]}\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 2)\n",
        "\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "best_parameters = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "print('best_parameters : ', best_parameters)\n",
        "print('best_accuracy : ', best_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShXqOJL47hCE",
        "colab_type": "text"
      },
      "source": [
        "# Plot Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJdL7PP_7jir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "modulation_order = []\n",
        "modulation_order_dict = dict()\n",
        "\n",
        "for key,value in output.items():\n",
        "    modulation_order_dict[np.argmax(value)] = str(key)\n",
        "    \n",
        "for i in range(8):\n",
        "    modulation_order.append(modulation_order_dict[i])\n",
        "    \n",
        "    \n",
        "    \n",
        "cmDataFrame = pd.DataFrame(cm_norm, index=modulation_order, columns = modulation_order)\n",
        "plt.figure(figsize=(6, 5))\n",
        "ax = sns.heatmap(cmDataFrame, annot=True, annot_kws={\"size\": 8}, fmt='.2f', linewidths=.5, cmap=\"Greens\")\n",
        "\n",
        "plt.title(f\"AANN Confusion Matrix (SNR={snr})\")\n",
        "plt.xlabel(\"Predicted label  \\n\\n TrainAcc={:.2}, TestAcc={:.2}\".format(acc_train,acc_test), fontsize=8)\n",
        "plt.ylabel(\"True lable\", fontsize=8)\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\", fontsize=8)\n",
        "plt.setp(ax.get_yticklabels(), fontsize=8)\n",
        "fig = ax.get_figure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8eHSHvA7_ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "fig.savefig(dic+f\"ANN2-CrossVal-132-132-ba{batch}-ep{epoch}(SNR={snr}).png\", dpi=175, bbox_inches='tight')\n",
        "print(\"Plot Saved!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRGfQj5oJH9B",
        "colab_type": "text"
      },
      "source": [
        "# Plot Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJx_GdLiJG2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import pydot\n",
        "import pydotplus\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "keras.utils.vis_utils.pydot = pydot\n",
        "file = ''\n",
        "plot_model(classifier,show_shapes=True,show_layer_names=False, to_file='model.png' , rankdir='LR')\n",
        "plot_model(classifier,show_shapes=True,show_layer_names=False, to_file='model.eps' , rankdir='LR')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_d7UlrRJTdJ",
        "colab_type": "text"
      },
      "source": [
        "# Plot accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofyw4cqWJZQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
        "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
        "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
        "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
        "    \n",
        "    if len(loss_list) == 0:\n",
        "        print('Loss is missing in history')\n",
        "        return \n",
        "    \n",
        "    ## As loss always exists\n",
        "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
        "    \n",
        "    ## Loss\n",
        "    plt.figure(1)\n",
        "    for l in loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    for l in val_loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))  \n",
        "    \n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    ## Accuracy\n",
        "    plt.figure(2)\n",
        "    for l in acc_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "    for l in val_acc_list:    \n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvZtjPOeJadx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history(classifier.history)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}