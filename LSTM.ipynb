{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohsenJadidi/Automatic-Modulation-Classification-AMC/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0dBrWRWh7UO",
        "colab_type": "code",
        "outputId": "47477528-2aeb-4721-e54f-b34ca0d60e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR0ATiKBk6rG",
        "colab_type": "text"
      },
      "source": [
        "# Importing the dataset (Copy from CNN.ipynb and merge cells)\n",
        "without Reshape(2 end line)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPn2IGIXTG6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "be9bf9ec-6ca5-4836-eaf1-54c21387bbd6"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "fileName = 'RML2016.10a_dict.pkl'\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/\"+fileName,'rb') as f:\n",
        "  data = pickle.load(f,encoding='bytes')\n",
        " \n",
        "X = []\n",
        "labels = [] # label each example by a pair (modulation type, snr)\n",
        "total_examples = 0\n",
        "analog = [b'AM-DSB', b'AM-SSB', b'WBFM']\n",
        "\n",
        "for mod_type, snr in data.keys():\n",
        "    if (mod_type not in analog):      \n",
        "        current_matrix = data[(mod_type, snr)]        \n",
        "        total_examples += current_matrix.shape[0]\n",
        "        for i in range(current_matrix.shape[0]):\n",
        "            X.append(current_matrix[i])\n",
        "            labels.append((str(mod_type, 'ascii'), snr)) # mod_type is of type bytes\n",
        "    \n",
        "X = np.array(X)         # First row is QPSK snr=2, seconde is PAM4 snr=8 , ...\n",
        "labels = np.array(labels)\n",
        "\n",
        "y = labels[:,0]\n",
        "\n",
        "print(f'loaded {total_examples} signal vectors into X{X.shape} and their corresponding'\n",
        "      f' labels into labels{labels.shape}')  \n",
        "# print(np.unique(labels[:,0]))\n",
        "\n",
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)\n",
        "onehotencoder = OneHotEncoder()\n",
        "y = onehotencoder.fit_transform(y.reshape(-1,1)).toarray()\n",
        "\n",
        "snrList = [str(2*i-20) for i in range(20)]  # snrList = -20, -18, -16 , ... ,0, ... ,18\n",
        "snr = snrList[19]\n",
        "numberOfEachExamples = 1000\n",
        "print(\"SNR :\", snr)\n",
        "\n",
        "output = [[labels[i*numberOfEachExamples, 0],y[i*numberOfEachExamples]] for i in range(int(X.shape[0]/numberOfEachExamples))]\n",
        "output = dict(output)\n",
        "\n",
        "X_snr = []\n",
        "y_snr = []\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "    if labels[i,1] == snr:\n",
        "        X_snr.append(X[i])\n",
        "        y_snr.append(y[i])\n",
        "\n",
        "X_snr = np.array(X_snr)\n",
        "y_snr = np.array(y_snr)  \n",
        "\n",
        "# Change IQ to amplitude and phase\n",
        "'''\n",
        "from math import sqrt, atan2, pow, pi\n",
        "\n",
        "AmpPhs_snr = np.zeros_like(X_snr)\n",
        "for i in range(X_snr.shape[0]):\n",
        "    for t in range(X_snr.shape[2]):\n",
        "        AmpPhs_snr[i,0,t] = sqrt(pow(X_snr[i,0,t], 2) + pow(X_snr[i,1,t],2))\n",
        "        AmpPhs_snr[i,1,t] = (atan2(X_snr[i,0,t], X_snr[i,1,t])) / pi\n",
        "'''\n",
        "\n",
        "X_cmplx = X_snr[:,0,:] + 1j* X_snr[:,1,:]\n",
        "    \n",
        "X_amp = np.abs(X_cmplx)\n",
        "#X_amp = X_amp/(np.reshape(np.sqrt(np.mean(X_amp**2,axis=1)),(-1,1))*np.ones([1,128]))\n",
        "X_ang = np.arctan2(X_snr[:,1,:],X_snr[:,0,:])\n",
        "#X_ang = X_ang/np.pi\n",
        "    \n",
        "    \n",
        "X_amp = np.reshape(X_amp,(-1,1,128))\n",
        "X_ang = np.reshape(X_ang,(-1,1,128))\n",
        "    \n",
        "AmpPhs_snr = np.concatenate((X_amp,X_ang), axis=1) \n",
        "#AmpPhs_snr = np.transpose(np.array(AmpPhs_snr),(0,2,1))        \n",
        "  \n",
        "###### Splitting the dataset into the Training set and Test set ######\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(AmpPhs_snr, y_snr, test_size = 0.2, random_state = 0)\n",
        "# The below line better for Cross_val part\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_snr, y_snr, test_size = 1, random_state = 0)\n",
        "\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "# StandardScaler expected <= 2.\n",
        "#X_train = X_train.reshape([6400,256])\n",
        "X_train = X_train.reshape([X_train.shape[0],256])\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_train = X_train.reshape([X_train.shape[0],2,128])\n",
        "#X_test = X_test.reshape([1600,256])\n",
        "X_test = X_test.reshape([X_test.shape[0],256])\n",
        "X_test = sc.transform(X_test)\n",
        "X_test = X_test.reshape([X_test.shape[0],2,128])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded 160000 signal vectors into X(160000, 2, 128) and their corresponding labels into labels(160000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR : 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drh0_kLlLXWK",
        "colab_type": "text"
      },
      "source": [
        "## Import Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9wXGX95LU7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input\n",
        "from keras.layers import add\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import BatchNormalization, SpatialDropout1D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9wgTgaCsQaAz"
      },
      "source": [
        "#Making LSTM0 model\n",
        "(Thesis :DEEP NEURAL NETWORK ARCHITECTURES FOR MODULATION CLASSIFICATION)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A-DMS2dT4xy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "8b5f99fa-487c-4fa7-d22c-5b5547501ec7"
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "\n",
        "dout = 0.8\n",
        "classifier.add(LSTM(128, input_shape =  (2,128), activation = 'relu'))\n",
        "classifier.add(Dropout(dout))\n",
        "classifier.add(Reshape(target_shape = (1,128)))\n",
        "classifier.add(LSTM(128, activation = 'relu'))\n",
        "classifier.add(Dropout(dout))\n",
        "\n",
        "\n",
        "#classifier.add(Flatten())\n",
        "#classifier.add(Dense(output_dim = 128 , activation = 'relu')) # hidden layer\n",
        "#classifier.add(Dropout(dout))\n",
        "classifier.add(Dense(output_dim = 8, activation = 'softmax'))\n",
        "\n",
        "adamOpt = keras.optimizers.adam(lr=0.001)\n",
        "\n",
        "classifier.compile(optimizer = adamOpt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "print(\"Model Created!\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_34 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "reshape_6 (Reshape)          (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_35 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 264,200\n",
            "Trainable params: 264,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Created!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=8)`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2h4CMVaam-i",
        "colab_type": "text"
      },
      "source": [
        "#Making LSTM1 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_LTHEgFamWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "8dddd332-5fad-49d9-c283-bc3868f34c71"
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "\n",
        "dout = 0.7\n",
        "classifier.add(LSTM(128, input_shape =  (2,128), activation = 'tanh', return_sequences=True, recurrent_dropout=0.2))\n",
        "classifier.add(SpatialDropout1D(0.5))\n",
        "#classifier.add(BatchNormalization())\n",
        "#classifier.add(Dropout(dout))\n",
        "# classifier.add(Reshape(target_shape = (1,128)))\n",
        "classifier.add(LSTM(128, activation = 'tanh', return_sequences=True, recurrent_dropout=0.2))\n",
        "classifier.add(SpatialDropout1D(0.5))\n",
        "#classifier.add(BatchNormalization())\n",
        "#classifier.add(Dropout(dout))\n",
        "\n",
        "\n",
        "classifier.add(Flatten())\n",
        "#classifier.add(BatchNormalization())\n",
        "#classifier.add(Dense(output_dim = 128 , activation = 'relu')) # hidden layer\n",
        "#classifier.add(Dropout(dout))\n",
        "\n",
        "classifier.add(Dense(output_dim = 8, activation = 'softmax'))\n",
        "\n",
        "adamOpt = keras.optimizers.adam(lr=0.001)\n",
        "\n",
        "classifier.compile(optimizer = adamOpt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "print(\"Model Created!\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_40 (LSTM)               (None, 2, 32)             20608     \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 2, 32)             0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 21,128\n",
            "Trainable params: 21,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Created!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=8)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct6SfO0K3RPR",
        "colab_type": "text"
      },
      "source": [
        "# Fitting model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txz8QArgZaQj",
        "colab_type": "code",
        "outputId": "60b790a1-af15-4f14-8ed1-2cbaa1233a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch = 64\n",
        "epoch = 100\n",
        "history = classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch, validation_data=(X_test, y_test))\n",
        "#history = classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/100\n",
            "6400/6400 [==============================] - 7s 1ms/step - loss: 2.1250 - acc: 0.1406 - val_loss: 2.0417 - val_acc: 0.2106\n",
            "Epoch 2/100\n",
            "6400/6400 [==============================] - 1s 191us/step - loss: 2.0371 - acc: 0.1958 - val_loss: 1.9793 - val_acc: 0.2925\n",
            "Epoch 3/100\n",
            "6400/6400 [==============================] - 1s 189us/step - loss: 1.9703 - acc: 0.2403 - val_loss: 1.8953 - val_acc: 0.3456\n",
            "Epoch 4/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.8910 - acc: 0.2823 - val_loss: 1.8004 - val_acc: 0.3706\n",
            "Epoch 5/100\n",
            "6400/6400 [==============================] - 1s 188us/step - loss: 1.7933 - acc: 0.3233 - val_loss: 1.6977 - val_acc: 0.3975\n",
            "Epoch 6/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.7126 - acc: 0.3416 - val_loss: 1.5988 - val_acc: 0.4269\n",
            "Epoch 7/100\n",
            "6400/6400 [==============================] - 1s 188us/step - loss: 1.6272 - acc: 0.3669 - val_loss: 1.5062 - val_acc: 0.4481\n",
            "Epoch 8/100\n",
            "6400/6400 [==============================] - 1s 193us/step - loss: 1.5456 - acc: 0.3923 - val_loss: 1.4316 - val_acc: 0.4688\n",
            "Epoch 9/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.4843 - acc: 0.4048 - val_loss: 1.3695 - val_acc: 0.4950\n",
            "Epoch 10/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 1.4485 - acc: 0.4108 - val_loss: 1.3210 - val_acc: 0.4869\n",
            "Epoch 11/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 1.4068 - acc: 0.4122 - val_loss: 1.2770 - val_acc: 0.4981\n",
            "Epoch 12/100\n",
            "6400/6400 [==============================] - 1s 189us/step - loss: 1.3556 - acc: 0.4356 - val_loss: 1.2350 - val_acc: 0.5075\n",
            "Epoch 13/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 1.3351 - acc: 0.4398 - val_loss: 1.2044 - val_acc: 0.5081\n",
            "Epoch 14/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.2896 - acc: 0.4616 - val_loss: 1.1714 - val_acc: 0.5231\n",
            "Epoch 15/100\n",
            "6400/6400 [==============================] - 1s 189us/step - loss: 1.2648 - acc: 0.4684 - val_loss: 1.1479 - val_acc: 0.5206\n",
            "Epoch 16/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.2491 - acc: 0.4691 - val_loss: 1.1249 - val_acc: 0.5231\n",
            "Epoch 17/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.2250 - acc: 0.4842 - val_loss: 1.0975 - val_acc: 0.5363\n",
            "Epoch 18/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.2026 - acc: 0.4766 - val_loss: 1.0899 - val_acc: 0.5212\n",
            "Epoch 19/100\n",
            "6400/6400 [==============================] - 1s 196us/step - loss: 1.1919 - acc: 0.4855 - val_loss: 1.0704 - val_acc: 0.5350\n",
            "Epoch 20/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.1790 - acc: 0.4908 - val_loss: 1.0527 - val_acc: 0.5450\n",
            "Epoch 21/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.1545 - acc: 0.4888 - val_loss: 1.0437 - val_acc: 0.5288\n",
            "Epoch 22/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.1498 - acc: 0.4892 - val_loss: 1.0306 - val_acc: 0.5381\n",
            "Epoch 23/100\n",
            "6400/6400 [==============================] - 1s 189us/step - loss: 1.1289 - acc: 0.5014 - val_loss: 1.0220 - val_acc: 0.5325\n",
            "Epoch 24/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 1.1202 - acc: 0.5070 - val_loss: 1.0124 - val_acc: 0.5444\n",
            "Epoch 25/100\n",
            "6400/6400 [==============================] - 1s 193us/step - loss: 1.1072 - acc: 0.5083 - val_loss: 1.0087 - val_acc: 0.5375\n",
            "Epoch 26/100\n",
            "6400/6400 [==============================] - 1s 194us/step - loss: 1.0991 - acc: 0.5156 - val_loss: 0.9987 - val_acc: 0.5513\n",
            "Epoch 27/100\n",
            "6400/6400 [==============================] - 1s 191us/step - loss: 1.0869 - acc: 0.5206 - val_loss: 0.9952 - val_acc: 0.5550\n",
            "Epoch 28/100\n",
            "6400/6400 [==============================] - 1s 198us/step - loss: 1.0914 - acc: 0.5150 - val_loss: 0.9884 - val_acc: 0.5444\n",
            "Epoch 29/100\n",
            "6400/6400 [==============================] - 1s 195us/step - loss: 1.0709 - acc: 0.5184 - val_loss: 0.9828 - val_acc: 0.5594\n",
            "Epoch 30/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 1.0643 - acc: 0.5192 - val_loss: 0.9765 - val_acc: 0.5581\n",
            "Epoch 31/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 1.0685 - acc: 0.5298 - val_loss: 0.9721 - val_acc: 0.5575\n",
            "Epoch 32/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 1.0575 - acc: 0.5248 - val_loss: 0.9687 - val_acc: 0.5519\n",
            "Epoch 33/100\n",
            "6400/6400 [==============================] - 1s 193us/step - loss: 1.0467 - acc: 0.5269 - val_loss: 0.9584 - val_acc: 0.5731\n",
            "Epoch 34/100\n",
            "6400/6400 [==============================] - 1s 197us/step - loss: 1.0370 - acc: 0.5372 - val_loss: 0.9568 - val_acc: 0.5737\n",
            "Epoch 35/100\n",
            "6400/6400 [==============================] - 1s 193us/step - loss: 1.0466 - acc: 0.5337 - val_loss: 0.9513 - val_acc: 0.5731\n",
            "Epoch 36/100\n",
            "6400/6400 [==============================] - 1s 196us/step - loss: 1.0334 - acc: 0.5395 - val_loss: 0.9471 - val_acc: 0.5769\n",
            "Epoch 37/100\n",
            "6400/6400 [==============================] - 1s 191us/step - loss: 1.0293 - acc: 0.5386 - val_loss: 0.9514 - val_acc: 0.5675\n",
            "Epoch 38/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 1.0114 - acc: 0.5431 - val_loss: 0.9446 - val_acc: 0.5575\n",
            "Epoch 39/100\n",
            "6400/6400 [==============================] - 1s 193us/step - loss: 1.0177 - acc: 0.5413 - val_loss: 0.9387 - val_acc: 0.5663\n",
            "Epoch 40/100\n",
            "6400/6400 [==============================] - 1s 191us/step - loss: 1.0133 - acc: 0.5402 - val_loss: 0.9420 - val_acc: 0.5625\n",
            "Epoch 41/100\n",
            "6400/6400 [==============================] - 1s 194us/step - loss: 1.0138 - acc: 0.5414 - val_loss: 0.9352 - val_acc: 0.5700\n",
            "Epoch 42/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 1.0049 - acc: 0.5420 - val_loss: 0.9339 - val_acc: 0.5731\n",
            "Epoch 43/100\n",
            "6400/6400 [==============================] - 1s 189us/step - loss: 0.9937 - acc: 0.5448 - val_loss: 0.9302 - val_acc: 0.5694\n",
            "Epoch 44/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 0.9988 - acc: 0.5508 - val_loss: 0.9321 - val_acc: 0.5775\n",
            "Epoch 45/100\n",
            "6400/6400 [==============================] - 1s 195us/step - loss: 0.9887 - acc: 0.5531 - val_loss: 0.9248 - val_acc: 0.5744\n",
            "Epoch 46/100\n",
            "6400/6400 [==============================] - 1s 194us/step - loss: 0.9834 - acc: 0.5603 - val_loss: 0.9251 - val_acc: 0.5744\n",
            "Epoch 47/100\n",
            "6400/6400 [==============================] - 1s 193us/step - loss: 0.9810 - acc: 0.5537 - val_loss: 0.9282 - val_acc: 0.5694\n",
            "Epoch 48/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 0.9785 - acc: 0.5661 - val_loss: 0.9213 - val_acc: 0.5800\n",
            "Epoch 49/100\n",
            "6400/6400 [==============================] - 1s 194us/step - loss: 0.9798 - acc: 0.5481 - val_loss: 0.9157 - val_acc: 0.5763\n",
            "Epoch 50/100\n",
            "6400/6400 [==============================] - 1s 194us/step - loss: 0.9740 - acc: 0.5608 - val_loss: 0.9124 - val_acc: 0.5775\n",
            "Epoch 51/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 0.9644 - acc: 0.5533 - val_loss: 0.9143 - val_acc: 0.5819\n",
            "Epoch 52/100\n",
            "6400/6400 [==============================] - 1s 190us/step - loss: 0.9699 - acc: 0.5689 - val_loss: 0.9113 - val_acc: 0.5756\n",
            "Epoch 53/100\n",
            "6400/6400 [==============================] - 1s 195us/step - loss: 0.9609 - acc: 0.5600 - val_loss: 0.9133 - val_acc: 0.5806\n",
            "Epoch 54/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 0.9574 - acc: 0.5695 - val_loss: 0.9096 - val_acc: 0.5869\n",
            "Epoch 55/100\n",
            "6400/6400 [==============================] - 1s 192us/step - loss: 0.9601 - acc: 0.5677 - val_loss: 0.9112 - val_acc: 0.5819\n",
            "Epoch 56/100\n",
            "1024/6400 [===>..........................] - ETA: 0s - loss: 0.9101 - acc: 0.5928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-068d6c39be34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#history = classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNGu7HtyhGc2",
        "colab_type": "text"
      },
      "source": [
        "# Prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6irYYHCZ6A2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test18)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_real = np.argmax(y_test18, axis=1)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_real, y_pred)\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "acc_test = classifier.evaluate(X_test18, y_test18)[1]\n",
        "#acc_train = classifier.evaluate(X_train, y_train)[1]\n",
        "\n",
        "print(\"Acc Test : \", acc_test)\n",
        "#print(\"Acc Train : \", acc_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShXqOJL47hCE",
        "colab_type": "text"
      },
      "source": [
        "# Plot Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJdL7PP_7jir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "modulation_order = []\n",
        "modulation_order_dict = dict()\n",
        "\n",
        "for key,value in output.items():\n",
        "    modulation_order_dict[np.argmax(value)] = str(key)\n",
        "    \n",
        "for i in range(8):\n",
        "    modulation_order.append(modulation_order_dict[i])\n",
        "    \n",
        "    \n",
        "    \n",
        "cmDataFrame = pd.DataFrame(cm_norm, index=modulation_order, columns = modulation_order)\n",
        "plt.figure(figsize=(6, 5))\n",
        "ax = sns.heatmap(cmDataFrame, annot=True, annot_kws={\"size\": 8}, fmt='.2f', linewidths=.5, cmap=\"Greens\")\n",
        "\n",
        "plt.title(f\"CNN Confusion Matrix (SNR={snr})\")\n",
        "plt.xlabel(\"Predicted label  \\n\\n TrainAcc={:.2}, TestAcc={:.2}\".format(acc_train,acc_test), fontsize=8)\n",
        "plt.ylabel(\"True lable\", fontsize=8)\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\", fontsize=8)\n",
        "plt.setp(ax.get_yticklabels(), fontsize=8)\n",
        "fig = ax.get_figure()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}