{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohsenJadidi/Automatic-Modulation-Classification-AMC/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0dBrWRWh7UO",
        "colab_type": "code",
        "outputId": "51a1a571-57ac-4342-acad-684a16fddc5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR0ATiKBk6rG",
        "colab_type": "text"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfzzfiDSuxMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "fileName = 'RML2016.10a_dict.pkl'\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/\"+fileName,'rb') as f:\n",
        "  data = pickle.load(f,encoding='bytes')\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjAg9T-0uzyh",
        "colab_type": "code",
        "outputId": "6795aa55-ac03-4050-9f25-2f66cb858831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "X = []\n",
        "labels = [] # label each example by a pair (modulation type, snr)\n",
        "total_examples = 0\n",
        "analog = [b'AM-DSB', b'AM-SSB', b'WBFM']\n",
        "\n",
        "for mod_type, snr in data.keys():\n",
        "    if (mod_type not in analog):      \n",
        "        current_matrix = data[(mod_type, snr)]        \n",
        "        total_examples += current_matrix.shape[0]\n",
        "        for i in range(current_matrix.shape[0]):\n",
        "            X.append(current_matrix[i])\n",
        "            labels.append((str(mod_type, 'ascii'), snr)) # mod_type is of type bytes\n",
        "    \n",
        "X = np.array(X)         # First row is QPSK snr=2, seconde is PAM4 snr=8 , ...\n",
        "labels = np.array(labels)\n",
        "\n",
        "y = labels[:,0]\n",
        "\n",
        "print(f'loaded {total_examples} signal vectors into X{X.shape} and their corresponding'\n",
        "      f' labels into labels{labels.shape}')  \n",
        "# print(np.unique(labels[:,0]))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded 160000 signal vectors into X(160000, 2, 128) and their corresponding labels into labels(160000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbeDr3FVv57v",
        "colab_type": "code",
        "outputId": "78333b99-55ca-4e44-895f-d45465c1cfae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)\n",
        "onehotencoder = OneHotEncoder()\n",
        "y = onehotencoder.fit_transform(y.reshape(-1,1)).toarray()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6iUKbJwKlT",
        "colab_type": "code",
        "outputId": "6e9a9b91-43f7-4b51-ac7f-0e8ed996ffb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "snrList = [str(2*i-20) for i in range(20)]  # snrList = -20, -18, -16 , ... ,0, ... ,18\n",
        "snr = snrList[19]\n",
        "numberOfEachExamples = 1000\n",
        "print(\"SNR :\", snr)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR : 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DiHGfSPwKb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = [[labels[i*numberOfEachExamples, 0],y[i*numberOfEachExamples]] for i in range(int(X.shape[0]/numberOfEachExamples))]\n",
        "output = dict(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OJ3GghKwrbs",
        "colab_type": "code",
        "outputId": "d3ff8a5e-38e6-4adf-d5ee-32c66b2bbd4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xsnr = np.zeros(shape=(X.shape[0],X.shape[1],X.shape[2]+1))\n",
        "for i in range(X.shape[0]):\n",
        "    snr = int(labels[i,1])\n",
        "    Xsnr[i,0,:] = np.insert(X[i,0,:],0,snr)\n",
        "    Xsnr[i,1,:] = np.insert(X[i,1,:],0,snr)\n",
        "    \n",
        "print(Xsnr.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160000, 2, 129)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx7l0G_3ww0w",
        "colab_type": "code",
        "outputId": "80325eac-20ac-4743-bb25-19c050d6b9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "###### Splitting the dataset into the Training set and Test set ######\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xsnr, y, test_size = 0.2, random_state = 0)\n",
        "# The below line better for Cross_val part\n",
        "#X_train, X_test, y_train, y_test = train_test_split(Xsnr, y, test_size = 1, random_state = 0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128000, 2, 129)\n",
            "(32000, 2, 129)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGeDKe8GLNJ9",
        "colab_type": "code",
        "outputId": "7eb564d4-8621-4c25-a681-bd98d46bcb42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X_train = X_train[:,:,1:] # snr important for train\n",
        "\n",
        "y_test18 = []\n",
        "X_test18 = []\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    if X_test[i,0,0] == 18:\n",
        "        X_test18.append(X_test[i])\n",
        "        y_test18.append(y_test[i])\n",
        "        \n",
        "X_test18 = np.array(X_test18)\n",
        "y_test18 = np.array(y_test18)        \n",
        "X_test18 = X_test18[:,:,1:]\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test18.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128000, 2, 128)\n",
            "(1653, 2, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4OinfCHLd8y",
        "colab_type": "code",
        "outputId": "2094b8f0-9da0-4b7d-c2e8-4b59bd69d2e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Change IQ to amplitude and phase\n",
        "X_cmplx = X_train[:,0,:] + 1j* X_train[:,1,:]    \n",
        "X_amp = np.abs(X_cmplx)\n",
        "X_ang = np.arctan2(X_train[:,1,:],X_train[:,0,:]) / np.pi\n",
        "    \n",
        "X_amp = np.reshape(X_amp,(-1,1,128))\n",
        "X_ang = np.reshape(X_ang,(-1,1,128))\n",
        "    \n",
        "X_train_AmpPhs = np.concatenate((X_amp,X_ang), axis=1) \n",
        "##\n",
        "X_cmplx = X_test18[:,0,:] + 1j* X_test18[:,1,:]    \n",
        "X_amp = np.abs(X_cmplx)\n",
        "X_ang = np.arctan2(X_test18[:,1,:],X_test18[:,0,:]) / np.pi\n",
        "    \n",
        "X_amp = np.reshape(X_amp,(-1,1,128))\n",
        "X_ang = np.reshape(X_ang,(-1,1,128))\n",
        "    \n",
        "X_test18_AmpPhs = np.concatenate((X_amp,X_ang), axis=1) \n",
        "##\n",
        "\n",
        "print(X_train_AmpPhs.shape)\n",
        "print(X_test18_AmpPhs.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128000, 2, 128)\n",
            "(1653, 2, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujxapqcRw1l3",
        "colab_type": "code",
        "outputId": "6dbcb02f-29db-4776-d8b4-b51dccf296cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = X_train.reshape([X_train.shape[0],256])\n",
        "#X_train = X_train_AmpPhs.reshape([X_train.shape[0],256])\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_train = X_train.reshape([X_train.shape[0],2,128])\n",
        "#X_test = X_test.reshape([1600,256])\n",
        "X_test18 = X_test18.reshape([X_test18.shape[0],256])\n",
        "#X_test18 = X_test18_AmpPhs.reshape([X_test18.shape[0],256])\n",
        "X_test18 = sc.transform(X_test18)\n",
        "X_test18 = X_test18.reshape([X_test18.shape[0],2,128])\n",
        "\n",
        "# Reshape\n",
        "X_train = X_train.reshape(-1,2, 128, 1)   #Reshape for CNN -  (6400,2,128)->(6400,2,128,1)!!\n",
        "X_test18 = X_test18.reshape(-1,2, 128, 1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test18.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128000, 2, 128, 1)\n",
            "(1653, 2, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5InZvNieUoTS",
        "colab_type": "text"
      },
      "source": [
        "# Making CNN0 model \n",
        "(Article : Convolutional Radio Modulation Recognition Networks - Timothy J. O’Shea)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ida-kcQ9Ub0f",
        "colab_type": "code",
        "outputId": "679d3c7c-30aa-4b37-e66f-fa8f59c81dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "dout = 0.5\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(1,3), input_shape =  (2,128,1), padding='same', activation = 'relu')) \n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Conv2D(filters=32,kernel_size=(2,3),  padding='same', activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(output_dim = 128 , activation = 'relu')) # hidden layer\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Dense(output_dim = 8 , activation = 'softmax'))\n",
        "\n",
        "#from keras import optimizers\n",
        "#adamOpt = optimizers.adam(lr = 0.01)\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#logger = keras.callbacks.TensorBoard(log_dir=\"./logs\", write_graph=True, histogram_freq=0)\n",
        "\n",
        "classifier.summary()\n",
        "print(\"Model Created!\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 2, 128, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 2, 128, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 2, 128, 32)        6176      \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 2, 128, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               1048704   \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 1,056,040\n",
            "Trainable params: 1,056,040\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Created!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=8)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAqdPV-N3Ae_",
        "colab_type": "text"
      },
      "source": [
        "#Making CNN1 model (one-convolutional-layer)\n",
        "(Thesis :DEEP NEURAL NETWORK ARCHITECTURES FOR MODULATION CLASSIFICATION)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaOTxksa3D2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "dout = 0.6\n",
        "\n",
        "classifier.add(Conv2D(256,1,3, input_shape =  (2,128,1), activation = 'relu')) # 256=number of filter\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(output_dim = 128 , activation = 'relu')) # hidden layer\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Dense(output_dim = 8 , activation = 'softmax'))\n",
        "\n",
        "#from keras import optimizers\n",
        "#adamOpt = optimizers.adam(lr = 0.01)\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#logger = keras.callbacks.TensorBoard(log_dir=\"./logs\", write_graph=True, histogram_freq=0)\n",
        "\n",
        "classifier.summary()\n",
        "print(\"Model Created!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2HVRLuRvC2h",
        "colab_type": "text"
      },
      "source": [
        "# Making CNN2 model  (two-convolutional-layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EPV9BVqvAZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "dout = 0.4\n",
        "classifier.add(Conv2D(256,(1,3), input_shape =  (2,128,1), activation = 'relu', padding='same')) # 256=number of filter\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Conv2D(80,(2,3), activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(output_dim = 128 , activation = 'relu')) # hidden layer\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Dense(output_dim = 8 , activation = 'softmax'))\n",
        "\n",
        "#from keras import optimizers\n",
        "#adamOpt = optimizers.adam(lr = 0.01)\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#logger = keras.callbacks.TensorBoard(log_dir=\"./logs\", write_graph=True, histogram_freq=0)\n",
        "\n",
        "classifier.summary()\n",
        "print(\"Model Created!\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFwbq2eup-98",
        "colab_type": "text"
      },
      "source": [
        "#Making CNN3 model (two-convolutional-layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EOnbMLu3Qpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "dout = 0.4\n",
        "\n",
        "classifier.add(Conv2D(80,2,3, activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Conv2D(256,1,3, input_shape =  (2,128,1), activation = 'relu')) # 256=number of filter\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(output_dim = 128 , activation = 'relu')) # hidden layer\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Dense(output_dim = 8 , activation = 'softmax'))\n",
        "\n",
        "#from keras import optimizers\n",
        "#adamOpt = optimizers.adam(lr = 0.01)\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#logger = keras.callbacks.TensorBoard(log_dir=\"./logs\", write_graph=True, histogram_freq=0)\n",
        "\n",
        "classifier.summary()\n",
        "print(\"Model Created!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcI2TeYzEwY6",
        "colab_type": "text"
      },
      "source": [
        "#Making CNN4 model (four-convolutional-layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EcNw2P4Ew_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "dout = 0.4\n",
        "classifier.add(Conv2D(256,1,3, input_shape =  (2,128,1), activation = 'relu')) # 256=number of filter\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Conv2D(256,2,3, activation = 'relu')) # 256=number of filter\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Conv2D(80,1,3, activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Conv2D(80,1,3, activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(output_dim = 128 , activation = 'relu')) # hidden layer\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Dense(output_dim = 8 , activation = 'softmax'))\n",
        "\n",
        "#from keras import optimizers\n",
        "#adamOpt = optimizers.adam(lr = 0.01)\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#logger = keras.callbacks.TensorBoard(log_dir=\"./logs\", write_graph=True, histogram_freq=0)\n",
        "\n",
        "classifier.summary()\n",
        "print(\"Model Created!\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv1KiftgFi9w",
        "colab_type": "text"
      },
      "source": [
        "#Making CNN5 model (five-convolutional-layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DceZWd-aFjkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "dout = 0.4\n",
        "classifier.add(Conv2D(384,1,3, input_shape =  (2,128,1), activation = 'relu')) \n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Conv2D(256,2,3, activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Conv2D(80,1,3, activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Conv2D(256,1,3, activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Conv2D(80,1,3, activation = 'relu'))\n",
        "classifier.add(Dropout(rate = dout))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(output_dim = 128 , activation = 'relu')) # hidden layer\n",
        "classifier.add(Dropout(rate = dout))\n",
        "classifier.add(Dense(output_dim = 8 , activation = 'softmax'))\n",
        "\n",
        "#from keras import optimizers\n",
        "#adamOpt = optimizers.adam(lr = 0.01)\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#logger = keras.callbacks.TensorBoard(log_dir=\"./logs\", write_graph=True, histogram_freq=0)\n",
        "\n",
        "classifier.summary()\n",
        "print(\"Model Created!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct6SfO0K3RPR",
        "colab_type": "text"
      },
      "source": [
        "# Fitting model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTK9sEg7uiRA",
        "colab_type": "code",
        "outputId": "389543e4-71ce-4429-a3c6-0ce5c37c0c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch = 1024\n",
        "epoch = 100\n",
        "\n",
        "history = classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch, validation_data=(X_test18, y_test18))\n",
        "#history = classifier.fit(X_train, y_train, batch_size = batch, epochs = epoch)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 128000 samples, validate on 1653 samples\n",
            "Epoch 1/100\n",
            "128000/128000 [==============================] - 5s 37us/step - loss: 1.9460 - acc: 0.2018 - val_loss: 1.6147 - val_acc: 0.3351\n",
            "Epoch 2/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.7630 - acc: 0.2766 - val_loss: 1.2000 - val_acc: 0.5426\n",
            "Epoch 3/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.6317 - acc: 0.3326 - val_loss: 0.9557 - val_acc: 0.6491\n",
            "Epoch 4/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.5369 - acc: 0.3722 - val_loss: 0.7735 - val_acc: 0.7145\n",
            "Epoch 5/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.4433 - acc: 0.4073 - val_loss: 0.6116 - val_acc: 0.7592\n",
            "Epoch 6/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.3758 - acc: 0.4295 - val_loss: 0.5342 - val_acc: 0.7586\n",
            "Epoch 7/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.3311 - acc: 0.4431 - val_loss: 0.4904 - val_acc: 0.7846\n",
            "Epoch 8/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.3003 - acc: 0.4582 - val_loss: 0.4519 - val_acc: 0.7871\n",
            "Epoch 9/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2774 - acc: 0.4656 - val_loss: 0.4368 - val_acc: 0.7901\n",
            "Epoch 10/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2663 - acc: 0.4714 - val_loss: 0.4375 - val_acc: 0.7846\n",
            "Epoch 11/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2555 - acc: 0.4756 - val_loss: 0.4192 - val_acc: 0.7931\n",
            "Epoch 12/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2448 - acc: 0.4784 - val_loss: 0.4135 - val_acc: 0.7931\n",
            "Epoch 13/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2372 - acc: 0.4806 - val_loss: 0.4149 - val_acc: 0.7919\n",
            "Epoch 14/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2283 - acc: 0.4851 - val_loss: 0.4058 - val_acc: 0.8022\n",
            "Epoch 15/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2207 - acc: 0.4889 - val_loss: 0.3929 - val_acc: 0.8010\n",
            "Epoch 16/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2179 - acc: 0.4889 - val_loss: 0.4001 - val_acc: 0.8106\n",
            "Epoch 17/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2125 - acc: 0.4931 - val_loss: 0.3895 - val_acc: 0.8088\n",
            "Epoch 18/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2104 - acc: 0.4941 - val_loss: 0.3955 - val_acc: 0.8010\n",
            "Epoch 19/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2047 - acc: 0.4980 - val_loss: 0.3826 - val_acc: 0.8076\n",
            "Epoch 20/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.2020 - acc: 0.4991 - val_loss: 0.3882 - val_acc: 0.8100\n",
            "Epoch 21/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1984 - acc: 0.4994 - val_loss: 0.3716 - val_acc: 0.8227\n",
            "Epoch 22/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1948 - acc: 0.5017 - val_loss: 0.3767 - val_acc: 0.8161\n",
            "Epoch 23/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1935 - acc: 0.5024 - val_loss: 0.3679 - val_acc: 0.8240\n",
            "Epoch 24/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1910 - acc: 0.5025 - val_loss: 0.3776 - val_acc: 0.8203\n",
            "Epoch 25/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1919 - acc: 0.5031 - val_loss: 0.3716 - val_acc: 0.8173\n",
            "Epoch 26/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1836 - acc: 0.5064 - val_loss: 0.3671 - val_acc: 0.8203\n",
            "Epoch 27/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1835 - acc: 0.5058 - val_loss: 0.3647 - val_acc: 0.8209\n",
            "Epoch 28/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1816 - acc: 0.5054 - val_loss: 0.3701 - val_acc: 0.8282\n",
            "Epoch 29/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1791 - acc: 0.5082 - val_loss: 0.3615 - val_acc: 0.8312\n",
            "Epoch 30/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1783 - acc: 0.5081 - val_loss: 0.3579 - val_acc: 0.8288\n",
            "Epoch 31/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1753 - acc: 0.5077 - val_loss: 0.3590 - val_acc: 0.8227\n",
            "Epoch 32/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1742 - acc: 0.5095 - val_loss: 0.3608 - val_acc: 0.8348\n",
            "Epoch 33/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1734 - acc: 0.5097 - val_loss: 0.3568 - val_acc: 0.8324\n",
            "Epoch 34/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1712 - acc: 0.5106 - val_loss: 0.3579 - val_acc: 0.8264\n",
            "Epoch 35/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1668 - acc: 0.5128 - val_loss: 0.3615 - val_acc: 0.8300\n",
            "Epoch 36/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1658 - acc: 0.5110 - val_loss: 0.3544 - val_acc: 0.8282\n",
            "Epoch 37/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1640 - acc: 0.5124 - val_loss: 0.3542 - val_acc: 0.8367\n",
            "Epoch 38/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1616 - acc: 0.5150 - val_loss: 0.3497 - val_acc: 0.8300\n",
            "Epoch 39/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1641 - acc: 0.5130 - val_loss: 0.3448 - val_acc: 0.8342\n",
            "Epoch 40/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1596 - acc: 0.5157 - val_loss: 0.3473 - val_acc: 0.8282\n",
            "Epoch 41/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1572 - acc: 0.5166 - val_loss: 0.3498 - val_acc: 0.8306\n",
            "Epoch 42/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1559 - acc: 0.5169 - val_loss: 0.3457 - val_acc: 0.8264\n",
            "Epoch 43/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1569 - acc: 0.5164 - val_loss: 0.3427 - val_acc: 0.8276\n",
            "Epoch 44/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1545 - acc: 0.5161 - val_loss: 0.3494 - val_acc: 0.8270\n",
            "Epoch 45/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1529 - acc: 0.5183 - val_loss: 0.3455 - val_acc: 0.8336\n",
            "Epoch 46/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1498 - acc: 0.5198 - val_loss: 0.3509 - val_acc: 0.8227\n",
            "Epoch 47/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1508 - acc: 0.5176 - val_loss: 0.3494 - val_acc: 0.8282\n",
            "Epoch 48/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1465 - acc: 0.5192 - val_loss: 0.3430 - val_acc: 0.8264\n",
            "Epoch 49/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1466 - acc: 0.5201 - val_loss: 0.3383 - val_acc: 0.8276\n",
            "Epoch 50/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1478 - acc: 0.5193 - val_loss: 0.3448 - val_acc: 0.8264\n",
            "Epoch 51/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1435 - acc: 0.5204 - val_loss: 0.3361 - val_acc: 0.8391\n",
            "Epoch 52/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1453 - acc: 0.5205 - val_loss: 0.3428 - val_acc: 0.8312\n",
            "Epoch 53/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1445 - acc: 0.5212 - val_loss: 0.3394 - val_acc: 0.8427\n",
            "Epoch 54/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1429 - acc: 0.5216 - val_loss: 0.3416 - val_acc: 0.8294\n",
            "Epoch 55/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1439 - acc: 0.5221 - val_loss: 0.3400 - val_acc: 0.8397\n",
            "Epoch 56/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1440 - acc: 0.5220 - val_loss: 0.3443 - val_acc: 0.8264\n",
            "Epoch 57/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1387 - acc: 0.5245 - val_loss: 0.3368 - val_acc: 0.8367\n",
            "Epoch 58/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1385 - acc: 0.5234 - val_loss: 0.3311 - val_acc: 0.8342\n",
            "Epoch 59/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1367 - acc: 0.5255 - val_loss: 0.3330 - val_acc: 0.8270\n",
            "Epoch 60/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1341 - acc: 0.5256 - val_loss: 0.3303 - val_acc: 0.8415\n",
            "Epoch 61/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1312 - acc: 0.5296 - val_loss: 0.3280 - val_acc: 0.8379\n",
            "Epoch 62/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1286 - acc: 0.5269 - val_loss: 0.3319 - val_acc: 0.8457\n",
            "Epoch 63/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1292 - acc: 0.5279 - val_loss: 0.3221 - val_acc: 0.8385\n",
            "Epoch 64/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1260 - acc: 0.5284 - val_loss: 0.3235 - val_acc: 0.8488\n",
            "Epoch 65/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1295 - acc: 0.5283 - val_loss: 0.3321 - val_acc: 0.8361\n",
            "Epoch 66/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1253 - acc: 0.5315 - val_loss: 0.3179 - val_acc: 0.8439\n",
            "Epoch 67/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1238 - acc: 0.5306 - val_loss: 0.3229 - val_acc: 0.8385\n",
            "Epoch 68/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1221 - acc: 0.5302 - val_loss: 0.3249 - val_acc: 0.8409\n",
            "Epoch 69/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1238 - acc: 0.5316 - val_loss: 0.3235 - val_acc: 0.8445\n",
            "Epoch 70/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1211 - acc: 0.5331 - val_loss: 0.3247 - val_acc: 0.8342\n",
            "Epoch 71/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1213 - acc: 0.5320 - val_loss: 0.3269 - val_acc: 0.8379\n",
            "Epoch 72/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1179 - acc: 0.5333 - val_loss: 0.3204 - val_acc: 0.8439\n",
            "Epoch 73/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1191 - acc: 0.5333 - val_loss: 0.3197 - val_acc: 0.8415\n",
            "Epoch 74/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1133 - acc: 0.5363 - val_loss: 0.3178 - val_acc: 0.8457\n",
            "Epoch 75/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1163 - acc: 0.5342 - val_loss: 0.3196 - val_acc: 0.8403\n",
            "Epoch 76/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1146 - acc: 0.5364 - val_loss: 0.3141 - val_acc: 0.8488\n",
            "Epoch 77/100\n",
            "128000/128000 [==============================] - 3s 23us/step - loss: 1.1116 - acc: 0.5375 - val_loss: 0.3106 - val_acc: 0.8445\n",
            "Epoch 78/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1069 - acc: 0.5392 - val_loss: 0.3142 - val_acc: 0.8367\n",
            "Epoch 79/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1060 - acc: 0.5390 - val_loss: 0.3200 - val_acc: 0.8433\n",
            "Epoch 80/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1086 - acc: 0.5360 - val_loss: 0.3160 - val_acc: 0.8403\n",
            "Epoch 81/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1067 - acc: 0.5382 - val_loss: 0.3151 - val_acc: 0.8373\n",
            "Epoch 82/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1069 - acc: 0.5385 - val_loss: 0.3113 - val_acc: 0.8475\n",
            "Epoch 83/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1055 - acc: 0.5401 - val_loss: 0.3126 - val_acc: 0.8445\n",
            "Epoch 84/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1044 - acc: 0.5392 - val_loss: 0.3172 - val_acc: 0.8391\n",
            "Epoch 85/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1038 - acc: 0.5392 - val_loss: 0.3101 - val_acc: 0.8397\n",
            "Epoch 86/100\n",
            "128000/128000 [==============================] - 3s 23us/step - loss: 1.1023 - acc: 0.5404 - val_loss: 0.3078 - val_acc: 0.8403\n",
            "Epoch 87/100\n",
            "128000/128000 [==============================] - 3s 23us/step - loss: 1.1030 - acc: 0.5394 - val_loss: 0.3189 - val_acc: 0.8361\n",
            "Epoch 88/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0996 - acc: 0.5409 - val_loss: 0.3072 - val_acc: 0.8451\n",
            "Epoch 89/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1002 - acc: 0.5418 - val_loss: 0.3052 - val_acc: 0.8590\n",
            "Epoch 90/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.1008 - acc: 0.5416 - val_loss: 0.3124 - val_acc: 0.8482\n",
            "Epoch 91/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0991 - acc: 0.5412 - val_loss: 0.3024 - val_acc: 0.8518\n",
            "Epoch 92/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0958 - acc: 0.5438 - val_loss: 0.3071 - val_acc: 0.8482\n",
            "Epoch 93/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0996 - acc: 0.5418 - val_loss: 0.3103 - val_acc: 0.8409\n",
            "Epoch 94/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0971 - acc: 0.5423 - val_loss: 0.3011 - val_acc: 0.8512\n",
            "Epoch 95/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0941 - acc: 0.5445 - val_loss: 0.3016 - val_acc: 0.8506\n",
            "Epoch 96/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0959 - acc: 0.5422 - val_loss: 0.3034 - val_acc: 0.8512\n",
            "Epoch 97/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0936 - acc: 0.5441 - val_loss: 0.2963 - val_acc: 0.8488\n",
            "Epoch 98/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0915 - acc: 0.5449 - val_loss: 0.3021 - val_acc: 0.8500\n",
            "Epoch 99/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0910 - acc: 0.5452 - val_loss: 0.3030 - val_acc: 0.8482\n",
            "Epoch 100/100\n",
            "128000/128000 [==============================] - 3s 24us/step - loss: 1.0888 - acc: 0.5483 - val_loss: 0.2943 - val_acc: 0.8548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVFgwssVfxtd",
        "colab_type": "text"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKe0m_39HiWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d86f8d3-d58a-4cab-8eb4-f2a5c36bea65"
      },
      "source": [
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "classifier.save(dic+f'SaveModel/CNN0-32(1,3)-32(2,3)-ba{batch}-ep{epoch}-(dout=0.5)-input(IQ)(SNR=all).h5')\n",
        "\n",
        "f = open(dic+f'SaveModel/CNN0-32(1,3)-32(2,3)-ba{batch}-ep{epoch}-(dout=0.5)-input(IQ)(SNR=all)-history.txt',\"w\")\n",
        "f.write( str(classifier.history.history) )\n",
        "f.close()\n",
        "\n",
        "print('Model Saved!')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNGu7HtyhGc2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Prediction(only SNR=18)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6irYYHCZ6A2C",
        "colab_type": "code",
        "outputId": "0c97d29a-7e7a-4ca7-b475-755aa83278d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "y_pred = classifier.predict(X_test18)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_real = np.argmax(y_test18, axis=1)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_real, y_pred)\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "acc_test = classifier.evaluate(X_test18, y_test18)[1]\n",
        "acc_train = classifier.evaluate(X_train, y_train)[1]\n",
        "\n",
        "print(\"Acc Test : \", acc_test)\n",
        "print(\"Acc Train : \", acc_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1653/1653 [==============================] - 0s 81us/step\n",
            "128000/128000 [==============================] - 10s 79us/step\n",
            "Acc Test :  0.8354506957408376\n",
            "Acc Train :  0.5644609375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShXqOJL47hCE",
        "colab_type": "text"
      },
      "source": [
        "# Plot Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6AbLWccANuo",
        "colab_type": "code",
        "outputId": "bbb672de-7109-4322-cad8-505a777b848f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "modulation_order = []\n",
        "modulation_order_dict = dict()\n",
        "\n",
        "for key,value in output.items():\n",
        "    modulation_order_dict[np.argmax(value)] = str(key)\n",
        "    \n",
        "for i in range(8):\n",
        "    modulation_order.append(modulation_order_dict[i])\n",
        "    \n",
        "acc_test = classifier.evaluate(X_test18, y_test18)[1]\n",
        "acc_train = classifier.evaluate(X_train, y_train)[1]\n",
        "\n",
        "print(\"Acc Test : \", acc_test)\n",
        "print(\"Acc Train : \", acc_train)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1653/1653 [==============================] - 0s 212us/step\n",
            "128000/128000 [==============================] - 11s 85us/step\n",
            "Acc Test :  0.8523895948566383\n",
            "Acc Train :  0.567703125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv5RzFyj_Cj1",
        "colab_type": "code",
        "outputId": "426e8afe-1737-413b-ce69-b65123b6e0f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "acc = []\n",
        "\n",
        "for snr in snrList:\n",
        "  print('SNR: ', snr)\n",
        "    \n",
        "  y_test_snr = []\n",
        "  X_test_snr = []\n",
        "  for i in range(X_test.shape[0]):\n",
        "    if X_test[i,0,0] == int(snr):\n",
        "      X_test_snr.append(X_test[i])\n",
        "      y_test_snr.append(y_test[i])\n",
        "        \n",
        "  X_test_snr = np.array(X_test_snr)\n",
        "  y_test_snr = np.array(y_test_snr)        \n",
        "  X_test_snr = X_test_snr[:,:,1:]\n",
        "  \n",
        "  X_test_snr = X_test_snr.reshape([X_test_snr.shape[0],256])\n",
        "  X_test_snr = sc.transform(X_test_snr)\n",
        "  X_test_snr = X_test_snr.reshape([X_test_snr.shape[0],2,128])\n",
        "  \n",
        "  X_test_snr = X_test_snr.reshape(-1,2, 128, 1) # For CNN\n",
        "    \n",
        "  acc_test = classifier.evaluate(X_test_snr, y_test_snr)[1]\n",
        "  acc.append(acc_test)\n",
        "  print(acc_test)\n",
        "  '''\n",
        "  y_pred = classifier.predict(X_test_snr)\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "  y_real = np.argmax(y_test_snr, axis=1)\n",
        "  # Making the Confusion Matrix\n",
        "  cm = confusion_matrix(y_real, y_pred)\n",
        "  cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    \n",
        "    \n",
        "  cmDataFrame = pd.DataFrame(cm_norm, index=modulation_order, columns = modulation_order)\n",
        "  plt.figure(figsize=(6, 5))\n",
        "  ax = sns.heatmap(cmDataFrame, annot=True, annot_kws={\"size\": 8}, fmt='.2f', linewidths=.5, cmap=\"Blues\")\n",
        "\n",
        "  plt.title(f\"CNN Confusion Matrix (SNR={snr})\")\n",
        "  plt.xlabel(\"Predicted label  \\n\\n TrainAcc={:.2}, TestAcc={:.2}\".format(acc_train,acc_test), fontsize=8)\n",
        "  plt.ylabel(\"True lable\", fontsize=8)\n",
        "  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\", fontsize=8)\n",
        "  plt.setp(ax.get_yticklabels(), fontsize=8)\n",
        "  fig = ax.get_figure()\n",
        "\n",
        "  fig.savefig(dic+f\"/Pic/CNN/CNN0-ba{batch}-ep{epoch}-(dout=0.6)-input(IQ)(SNR={snr}).png\", dpi=175, bbox_inches='tight')\n",
        "  fig.savefig(dic+f\"/Pic/CNN/CNN0-ba{batch}-ep{epoch}-(dout=0.6)-input(IQ)(SNR={snr}).eps\", bbox_inches='tight')\n",
        "  print(\"Plot Saved!\")\n",
        "'''\n",
        "\n",
        "  del(y_test_snr)\n",
        "  del(X_test_snr)\n",
        "      \n",
        "print(acc)    \n",
        "    "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR:  -20\n",
            "1636/1636 [==============================] - 0s 91us/step\n",
            "0.12775061124694376\n",
            "SNR:  -18\n",
            "1630/1630 [==============================] - 0s 78us/step\n",
            "0.1239263803955236\n",
            "SNR:  -16\n",
            "1606/1606 [==============================] - 0s 62us/step\n",
            "0.1226650062637638\n",
            "SNR:  -14\n",
            "1633/1633 [==============================] - 0s 59us/step\n",
            "0.1267605633802817\n",
            "SNR:  -12\n",
            "1567/1567 [==============================] - 0s 82us/step\n",
            "0.13146139115532568\n",
            "SNR:  -10\n",
            "1561/1561 [==============================] - 0s 78us/step\n",
            "0.18577834726105433\n",
            "SNR:  -8\n",
            "1605/1605 [==============================] - 0s 61us/step\n",
            "0.3320872274236144\n",
            "SNR:  -6\n",
            "1605/1605 [==============================] - 0s 47us/step\n",
            "0.41806853589981885\n",
            "SNR:  -4\n",
            "1600/1600 [==============================] - 0s 50us/step\n",
            "0.488125\n",
            "SNR:  -2\n",
            "1642/1642 [==============================] - 0s 63us/step\n",
            "0.6132764920102257\n",
            "SNR:  0\n",
            "1570/1570 [==============================] - 0s 60us/step\n",
            "0.7560509554140128\n",
            "SNR:  2\n",
            "1577/1577 [==============================] - 0s 69us/step\n",
            "0.813570069752695\n",
            "SNR:  4\n",
            "1555/1555 [==============================] - 0s 76us/step\n",
            "0.8347266883712107\n",
            "SNR:  6\n",
            "1598/1598 [==============================] - 0s 52us/step\n",
            "0.8166458069606777\n",
            "SNR:  8\n",
            "1568/1568 [==============================] - 0s 50us/step\n",
            "0.8239795918367347\n",
            "SNR:  10\n",
            "1542/1542 [==============================] - 0s 51us/step\n",
            "0.8378728922702923\n",
            "SNR:  12\n",
            "1598/1598 [==============================] - 0s 52us/step\n",
            "0.8229036292385249\n",
            "SNR:  14\n",
            "1616/1616 [==============================] - 0s 66us/step\n",
            "0.817450495049505\n",
            "SNR:  16\n",
            "1638/1638 [==============================] - 0s 51us/step\n",
            "0.8394383393655621\n",
            "SNR:  18\n",
            "1653/1653 [==============================] - 0s 77us/step\n",
            "0.8318209317836773\n",
            "[0.12775061124694376, 0.1239263803955236, 0.1226650062637638, 0.1267605633802817, 0.13146139115532568, 0.18577834726105433, 0.3320872274236144, 0.41806853589981885, 0.488125, 0.6132764920102257, 0.7560509554140128, 0.813570069752695, 0.8347266883712107, 0.8166458069606777, 0.8239795918367347, 0.8378728922702923, 0.8229036292385249, 0.817450495049505, 0.8394383393655621, 0.8318209317836773]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_d7UlrRJTdJ",
        "colab_type": "text"
      },
      "source": [
        "# Plot accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofyw4cqWJZQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
        "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
        "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
        "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
        "    \n",
        "    if len(loss_list) == 0:\n",
        "        print('Loss is missing in history')\n",
        "        return \n",
        "    \n",
        "    ## As loss always exists\n",
        "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
        "    \n",
        "    ## Loss\n",
        "    plt.figure(1)\n",
        "    for l in loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    for l in val_loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))  \n",
        "    \n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    ## Accuracy\n",
        "    plt.figure(2)\n",
        "    for l in acc_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "    for l in val_acc_list:    \n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvZtjPOeJadx",
        "colab_type": "code",
        "outputId": "2a9aa6e6-88d7-4770-ff97-c2e53e7943db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "plot_history(classifier.history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLGEYY4wJiiUMY4wxQfn/kMrcLhm+U3gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQoREdGRpBARER3/AClhpfCPwA1CAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYsdM-_E0JOk",
        "colab_type": "text"
      },
      "source": [
        "Laod Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YwGx5eVtNHf",
        "colab_type": "code",
        "outputId": "85ff63be-7a58-42eb-d3cb-99ac79b49eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "dic = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "\n",
        "model = load_model(dic+f'SaveModel/CNN0-128(1,3)-32(2,3)-ba{batch}-ep{epoch}-(dout=0.5)-input(IQ)(SNR=all).h5')\n",
        "\n",
        "print('Model loaded!')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pAIUxXfoxJD",
        "colab_type": "code",
        "outputId": "3173eb8d-0114-4bfb-94d2-510af79806ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier = model\n",
        "model.get_config()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'Conv2D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 2, 128, 1),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1, 1),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 128,\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'kernel_size': (1, 3),\n",
              "    'name': 'conv2d_5',\n",
              "    'padding': 'same',\n",
              "    'strides': (1, 1),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'name': 'dropout_7',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.5,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv2D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1, 1),\n",
              "    'filters': 32,\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'kernel_size': (2, 3),\n",
              "    'name': 'conv2d_6',\n",
              "    'padding': 'same',\n",
              "    'strides': (1, 1),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'name': 'dropout_8',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.5,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Flatten',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'name': 'flatten_3',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_5',\n",
              "    'trainable': True,\n",
              "    'units': 128,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'name': 'dropout_9',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.5,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_6',\n",
              "    'trainable': True,\n",
              "    'units': 8,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential_3'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}